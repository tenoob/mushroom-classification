{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15CQBM5lYpZWVVtHntWsiNtAx6yzPjegl",
      "authorship_tag": "ABX9TyM8+gqOSLZ3KDleU66KdBbR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tenoob/mushroom-classification/blob/main/training_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prince"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDh-erXd0HLz",
        "outputId": "7720a7f0-9ab3-4961-f7d5-34519fd52276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting prince\n",
            "  Downloading prince-0.13.1-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: altair<6.0.0,>=4.2.2 in /usr/local/lib/python3.10/dist-packages (from prince) (4.2.2)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from prince) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from prince) (1.3.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (4.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (1.26.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0.0,>=4.2.2->prince) (0.12.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.4.1->prince) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.4.1->prince) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.4.1->prince) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.2->prince) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.2->prince) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.2->prince) (3.5.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0.0,>=4.2.2->prince) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0.0,>=4.2.2->prince) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0.0,>=4.2.2->prince) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0.0,>=4.2.2->prince) (0.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.4.1->prince) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6.0.0,>=4.2.2->prince) (2.1.5)\n",
            "Downloading prince-0.13.1-py3-none-any.whl (415 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.8/415.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: prince\n",
            "Successfully installed prince-0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6IIgplAPk95N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/artificial intelligence/preprocessed_dataset.csv\")"
      ],
      "metadata": {
        "id": "tS2vWCwKm3Rz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "DtElTCXRnR-R",
        "outputId": "2e6aae27-c476-412a-c07f-b0a74d180f66"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 target  cap-shape  cap-surface  cap-color  bruises  odor  \\\n",
              "0           0      p          5            2          4        1     6   \n",
              "1           1      e          5            2          9        1     0   \n",
              "2           2      e          0            2          8        1     3   \n",
              "3           3      p          5            3          8        1     6   \n",
              "4           4      e          5            2          3        0     5   \n",
              "\n",
              "   gill-attachment  gill-spacing  gill-size  ...  stalk-surface-below-ring  \\\n",
              "0                1             0          1  ...                         2   \n",
              "1                1             0          0  ...                         2   \n",
              "2                1             0          0  ...                         2   \n",
              "3                1             0          1  ...                         2   \n",
              "4                1             1          0  ...                         2   \n",
              "\n",
              "   stalk-color-above-ring  stalk-color-below-ring  veil-type  veil-color  \\\n",
              "0                       7                       7          0           2   \n",
              "1                       7                       7          0           2   \n",
              "2                       7                       7          0           2   \n",
              "3                       7                       7          0           2   \n",
              "4                       7                       7          0           2   \n",
              "\n",
              "   ring-number  ring-type  spore-print-color  population  habitat  \n",
              "0            1          4                  2           3        5  \n",
              "1            1          4                  3           2        1  \n",
              "2            1          4                  3           2        3  \n",
              "3            1          4                  2           3        5  \n",
              "4            1          0                  3           0        1  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f68d5769-d7fc-4a05-bf6f-87e8f6ed4ec9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>target</th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>odor</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-size</th>\n",
              "      <th>...</th>\n",
              "      <th>stalk-surface-below-ring</th>\n",
              "      <th>stalk-color-above-ring</th>\n",
              "      <th>stalk-color-below-ring</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>ring-number</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>population</th>\n",
              "      <th>habitat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>p</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>e</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>e</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>p</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>e</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f68d5769-d7fc-4a05-bf6f-87e8f6ed4ec9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f68d5769-d7fc-4a05-bf6f-87e8f6ed4ec9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f68d5769-d7fc-4a05-bf6f-87e8f6ed4ec9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-40fe97aa-6363-4aef-afc4-5889211a3800\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40fe97aa-6363-4aef-afc4-5889211a3800')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-40fe97aa-6363-4aef-afc4-5889211a3800 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.iloc[:,2:]\n",
        "x.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "gF0CaQ0NsnRN",
        "outputId": "ff6cfb99-c694-422f-dce5-83281e8746bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
              "0          5            2          4        1     6                1   \n",
              "1          5            2          9        1     0                1   \n",
              "2          0            2          8        1     3                1   \n",
              "3          5            3          8        1     6                1   \n",
              "4          5            2          3        0     5                1   \n",
              "\n",
              "   gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
              "0             0          1           4            0  ...   \n",
              "1             0          0           4            0  ...   \n",
              "2             0          0           5            0  ...   \n",
              "3             0          1           5            0  ...   \n",
              "4             1          0           4            1  ...   \n",
              "\n",
              "   stalk-surface-below-ring  stalk-color-above-ring  stalk-color-below-ring  \\\n",
              "0                         2                       7                       7   \n",
              "1                         2                       7                       7   \n",
              "2                         2                       7                       7   \n",
              "3                         2                       7                       7   \n",
              "4                         2                       7                       7   \n",
              "\n",
              "   veil-type  veil-color  ring-number  ring-type  spore-print-color  \\\n",
              "0          0           2            1          4                  2   \n",
              "1          0           2            1          4                  3   \n",
              "2          0           2            1          4                  3   \n",
              "3          0           2            1          4                  2   \n",
              "4          0           2            1          0                  3   \n",
              "\n",
              "   population  habitat  \n",
              "0           3        5  \n",
              "1           2        1  \n",
              "2           2        3  \n",
              "3           3        5  \n",
              "4           0        1  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d62dd2e-107a-4c5a-83e2-609e9fc401c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>odor</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-size</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>stalk-shape</th>\n",
              "      <th>...</th>\n",
              "      <th>stalk-surface-below-ring</th>\n",
              "      <th>stalk-color-above-ring</th>\n",
              "      <th>stalk-color-below-ring</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>ring-number</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>population</th>\n",
              "      <th>habitat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d62dd2e-107a-4c5a-83e2-609e9fc401c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d62dd2e-107a-4c5a-83e2-609e9fc401c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d62dd2e-107a-4c5a-83e2-609e9fc401c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9317c40e-0a26-4fd1-b917-d7b85f8bed0d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9317c40e-0a26-4fd1-b917-d7b85f8bed0d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9317c40e-0a26-4fd1-b917-d7b85f8bed0d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dimentionality reduction\n",
        "\"\"\"import prince\n",
        "mca = prince.MCA()\n",
        "x_mca = mca.fit_transform(x)\n",
        "x_mca.head()\"\"\""
      ],
      "metadata": {
        "id": "zKlgwzuKz9Jq",
        "outputId": "25f64352-8506-4075-9fd5-7b6f440e661b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import prince\\nmca = prince.MCA()\\nx_mca = mca.fit_transform(x)\\nx_mca.head()'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df.iloc[:,1]\n",
        "y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "ZATgJ-1gnTnU",
        "outputId": "88fe03b5-7ce7-4e2f-d04a-22f0358dea8f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    p\n",
              "1    e\n",
              "2    e\n",
              "3    p\n",
              "4    e\n",
              "Name: target, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "m9619lfetHaS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afBZRyDBtZkV",
        "outputId": "f5c7dcb2-cd6a-4631-8f05-d79f177db699"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=45)"
      ],
      "metadata": {
        "id": "cq02JYRktjno"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape,y_train.shape)\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp8t6JMittXr",
        "outputId": "ff7ce169-a6a7-4912-ad64-14d4aafe7f5b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6499, 22) (6499,)\n",
            "(1625, 22) (1625,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic regression\n",
        "#random forest\n",
        "#light gbm\n",
        "#xgboost\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "\n",
        "pipe = Pipeline([(\"classifier\",LogisticRegression())])\n",
        "\n",
        "get_param = [\n",
        "    {\"classifier\":[LogisticRegression()],\n",
        "     \"classifier__penalty\":[\"l1\",\"l2\",\"elasticnet\"],\n",
        "     \"classifier__C\":np.logspace(0,4,10),\n",
        "     #\"classifier_fit_intercept\" : [\"True\",\"False\"],\n",
        "     \"classifier__solver\" : [\"newton-cg\",\"lbfgs\",\"liblinear\"],\n",
        "     \"classifier__max_iter\" : [100,150,200,300],\n",
        "     #\"classifier_class_weight\": [\"balanced\",None]\n",
        "     \"classifier__verbose\" : [2],\n",
        "     \"classifier__n_jobs\" : [-1]},\n",
        "    {\n",
        "      \"classifier\":[RandomForestClassifier()],\n",
        "      \"classifier__n_estimators\":[10,100,1000],\n",
        "      \"classifier__max_depth\":[1,5,10],\n",
        "      \"classifier__max_features\":[\"auto\",\"sqrt\",\"log2\"],\n",
        "      \"classifier__min_samples_split\":[2,5,10],\n",
        "      \"classifier__min_samples_leaf\":[1,2,5],\n",
        "      \"classifier__bootstrap\":[True,False]\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "gridSearch = GridSearchCV(pipe,get_param,cv=10,verbose=1,n_jobs=-1,scoring=\"accuracy\")\n",
        "best_model = gridSearch.fit(x_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSA92L0SXOz7",
        "outputId": "367f4fca-f908-4ae3-9659-9043970db8ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 846 candidates, totalling 8460 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
            "3620 fits failed out of a total of 8460.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 427, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 427, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 427, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 427, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "400 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 427, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 66, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1620 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1152, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 427, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1145, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 638, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.96445514 0.9526078  0.95245419 0.95214626\n",
            "        nan        nan        nan        nan        nan 0.96445514\n",
            " 0.9526078  0.95199241 0.95214626        nan        nan        nan\n",
            "        nan        nan 0.96430129 0.9526078  0.95183857 0.95214626\n",
            "        nan        nan        nan        nan        nan 0.96460898\n",
            " 0.9526078  0.9526078  0.95214626        nan        nan        nan\n",
            "        nan        nan 0.97076449 0.95691644 0.95753182 0.95660898\n",
            "        nan        nan        nan        nan        nan 0.97122603\n",
            " 0.95691644 0.95614745 0.95660898        nan        nan        nan\n",
            "        nan        nan 0.97091834 0.95691644 0.95583975 0.95660898\n",
            "        nan        nan        nan        nan        nan 0.97076449\n",
            " 0.95691644 0.95707005 0.95660898        nan        nan        nan\n",
            "        nan        nan 0.97338082 0.96337822 0.96384046 0.9619936\n",
            "        nan        nan        nan        nan        nan 0.97338082\n",
            " 0.96337822 0.96107195 0.9619936         nan        nan        nan\n",
            "        nan        nan 0.97338082 0.96337822 0.95999384 0.9619936\n",
            "        nan        nan        nan        nan        nan 0.97338082\n",
            " 0.96337822 0.96322461 0.9619936         nan        nan        nan\n",
            "        nan        nan 0.97338082 0.96984141 0.96645585 0.96722484\n",
            "        nan        nan        nan        nan        nan 0.97384236\n",
            " 0.96984141 0.96184118 0.96722484        nan        nan        nan\n",
            "        nan        nan 0.97384236 0.96984141 0.9627633  0.96722484\n",
            "        nan        nan        nan        nan        nan 0.97384236\n",
            " 0.96984141 0.96768614 0.96722484        nan        nan        nan\n",
            "        nan        nan 0.97384236 0.97307266 0.96645585 0.97137987\n",
            "        nan        nan        nan        nan        nan 0.97399621\n",
            " 0.97307266 0.9624568  0.97137987        nan        nan        nan\n",
            "        nan        nan 0.97415005 0.97307266 0.9618407  0.97137987\n",
            "        nan        nan        nan        nan        nan 0.97399621\n",
            " 0.97307266 0.97230295 0.97137987        nan        nan        nan\n",
            "        nan        nan 0.97415005 0.97399621 0.96753301 0.97384236\n",
            "        nan        nan        nan        nan        nan 0.97399621\n",
            " 0.97399621 0.96214887 0.97384236        nan        nan        nan\n",
            "        nan        nan 0.97415005 0.97399621 0.96091739 0.97384236\n",
            "        nan        nan        nan        nan        nan 0.97415005\n",
            " 0.97399621 0.97322603 0.97384236        nan        nan        nan\n",
            "        nan        nan 0.97415005 0.97353491 0.9673794  0.97384236\n",
            "        nan        nan        nan        nan        nan 0.97415005\n",
            " 0.97353491 0.96107218 0.97384236        nan        nan        nan\n",
            "        nan        nan 0.97415005 0.97353491 0.9635323  0.97384236\n",
            "        nan        nan        nan        nan        nan 0.97415005\n",
            " 0.97353491 0.97307266 0.97384236        nan        nan        nan\n",
            "        nan        nan 0.97415005 0.97307337 0.96784094 0.97338106\n",
            "        nan        nan        nan        nan        nan 0.97415005\n",
            " 0.97307337 0.96245703 0.97338106        nan        nan        nan\n",
            "        nan        nan 0.97415005 0.97307337 0.96414816 0.97338106\n",
            "        nan        nan        nan        nan        nan 0.97415005\n",
            " 0.97307337 0.97107123 0.97338106        nan        nan        nan\n",
            "        nan        nan 0.97415005 0.97307337 0.96814863 0.97322721\n",
            "        nan        nan        nan        nan        nan 0.97399621\n",
            " 0.97307337 0.96276425 0.97322721        nan        nan        nan\n",
            "        nan        nan 0.97415005 0.97307337 0.96384046 0.97322721\n",
            "        nan        nan        nan        nan        nan 0.97415005\n",
            " 0.97307337 0.9730736  0.97322721        nan        nan        nan\n",
            "        nan        nan 0.97399621 0.97322721 0.96676402 0.97307337\n",
            "        nan        nan        nan        nan        nan 0.97415005\n",
            " 0.97322721 0.96153301 0.97307337        nan        nan        nan\n",
            "        nan        nan 0.97415005 0.97322721 0.96214792 0.97307337\n",
            "        nan        nan        nan        nan        nan 0.97399621\n",
            " 0.97322721 0.97168851 0.97307337        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.84997464 0.8846033  0.88660045\n",
            " 0.88091241 0.88721512 0.88259879 0.84659405 0.89060282 0.88413891\n",
            " 0.86413678 0.89337039 0.88875335 0.8747607  0.88520991 0.8845995\n",
            " 0.87521797 0.88675501 0.88413796 0.84768022 0.8967543  0.8885995\n",
            " 0.85196231 0.88583312 0.88690814 0.83843451 0.883675   0.88444566\n",
            " 0.85043546 0.88736684 0.8867543  0.8767543  0.88475572 0.88460045\n",
            " 0.86274529 0.88444589 0.87998459 0.87182743 0.8859853  0.88752353\n",
            " 0.86290269 0.89337205 0.88352258 0.84598293 0.88214128 0.88598507\n",
            " 0.83906199 0.89198435 0.8847543  0.85875027 0.88613915 0.88552353\n",
            " 0.86059998 0.87536541 0.88537039        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.98984497 0.99045964 0.98969017 0.98984307 0.98999787 0.98984402\n",
            " 0.98999787 0.98999787 0.98984402 0.98953633 0.98999787 0.98969017\n",
            " 0.9892284  0.98969017 0.98953633 0.98969041 0.99030556 0.9899981\n",
            " 0.98984473 0.98938272 0.98892071 0.99107479 0.98907455 0.98892071\n",
            " 0.98830461 0.98938248 0.98892071 0.98938082 0.98953633 0.98984426\n",
            " 0.98953633 0.98999787 0.98984402 0.98799787 0.99030556 0.98984402\n",
            " 0.99045941 0.99015171 0.98984402 0.99030556 0.98969017 0.98984402\n",
            " 0.99045941 0.98999787 0.98953633 0.98892023 0.98938248 0.98892071\n",
            " 0.98907479 0.98907455 0.98892071 0.98953633 0.98938224 0.98892094\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         0.99907669 1.         1.\n",
            " 0.99953846 1.         1.         0.99969183 1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         0.99984592 1.         1.\n",
            " 0.99984615 1.         1.         0.99984615 1.         1.\n",
            " 1.         1.         1.                nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.8759853  0.89029015 0.88629394 0.85691004 0.88644684 0.8870627\n",
            " 0.86351879 0.88783264 0.88383051 0.86675785 0.88783003 0.88337039\n",
            " 0.86243665 0.89075643 0.8870627  0.85428138 0.88614128 0.88475264\n",
            " 0.8532156  0.89013962 0.88721536 0.86814152 0.88659998 0.88583264\n",
            " 0.87089131 0.88598649 0.88967951 0.87136375 0.88352803 0.8916788\n",
            " 0.85844163 0.87998317 0.88614105 0.8741427  0.87629015 0.8864466\n",
            " 0.87874861 0.87475335 0.88691028 0.86859998 0.8905995  0.8856788\n",
            " 0.85751997 0.8852156  0.88552424 0.87398127 0.88952685 0.88383122\n",
            " 0.85689913 0.87090743 0.8913711  0.86382174 0.89398673 0.88444732\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.99107432 0.98984402 0.98953633\n",
            " 0.98922816 0.98999787 0.98984402 0.99045964 0.99015195 0.98969017\n",
            " 0.98984402 0.99061325 0.9899981  0.99030556 0.9899981  0.9899981\n",
            " 0.98707408 0.98999787 0.98984402 0.98984378 0.98969017 0.98892071\n",
            " 0.98953609 0.98999787 0.9892284  0.98953609 0.9892284  0.98892071\n",
            " 0.99092094 0.9903058  0.98969017 0.98907479 0.98999787 0.98984402\n",
            " 0.99215195 0.99030556 0.98999787 0.98922982 0.98999787 0.98984402\n",
            " 0.98969136 0.98999787 0.98984402 0.98984473 0.99030556 0.98984402\n",
            " 0.98953657 0.98907455 0.98922864 0.98784378 0.98892071 0.98907479\n",
            " 0.99015171 0.98968994 0.98892071        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         0.99969231 0.99984615 1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         0.99984615 0.99984615 1.\n",
            " 0.99953846 0.99969231 1.         1.         1.         1.        ]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_model.best_estimator_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QTdKTsjc-wP",
        "outputId": "617219ac-4d4d-48e6-a7db-733d46477724"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline(steps=[('classifier',\n",
            "                 RandomForestClassifier(max_depth=10, n_estimators=10))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The mean accuracy of the model is:\",best_model.score(x_test,y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3oxDz8otLiW",
        "outputId": "3815cd48-8952-411d-bef2-5106004ade2e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean accuracy of the model is: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gridSearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "3uomyIAtudyD",
        "outputId": "4941683d-6780-409b-d94e-6a888d7ae4e7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10,\n",
              "             estimator=Pipeline(steps=[('classifier', LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid=[{'classifier': [LogisticRegression()],\n",
              "                          'classifier__C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
              "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
              "       3.59381366e+03, 1.00000000e+04]),\n",
              "                          'classifier__max_iter': [100, 150, 2...\n",
              "                          'classifier__solver': ['newton-cg', 'lbfgs',\n",
              "                                                 'liblinear'],\n",
              "                          'classifier__verbose': [2]},\n",
              "                         {'classifier': [RandomForestClassifier()],\n",
              "                          'classifier__bootstrap': [True, False],\n",
              "                          'classifier__max_depth': [1, 5, 10],\n",
              "                          'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
              "                          'classifier__min_samples_leaf': [1, 2, 5],\n",
              "                          'classifier__min_samples_split': [2, 5, 10],\n",
              "                          'classifier__n_estimators': [10, 100, 1000]}],\n",
              "             verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
              "             estimator=Pipeline(steps=[(&#x27;classifier&#x27;, LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid=[{&#x27;classifier&#x27;: [LogisticRegression()],\n",
              "                          &#x27;classifier__C&#x27;: array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
              "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
              "       3.59381366e+03, 1.00000000e+04]),\n",
              "                          &#x27;classifier__max_iter&#x27;: [100, 150, 2...\n",
              "                          &#x27;classifier__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
              "                                                 &#x27;liblinear&#x27;],\n",
              "                          &#x27;classifier__verbose&#x27;: [2]},\n",
              "                         {&#x27;classifier&#x27;: [RandomForestClassifier()],\n",
              "                          &#x27;classifier__bootstrap&#x27;: [True, False],\n",
              "                          &#x27;classifier__max_depth&#x27;: [1, 5, 10],\n",
              "                          &#x27;classifier__max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
              "                          &#x27;classifier__min_samples_leaf&#x27;: [1, 2, 5],\n",
              "                          &#x27;classifier__min_samples_split&#x27;: [2, 5, 10],\n",
              "                          &#x27;classifier__n_estimators&#x27;: [10, 100, 1000]}],\n",
              "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
              "             estimator=Pipeline(steps=[(&#x27;classifier&#x27;, LogisticRegression())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid=[{&#x27;classifier&#x27;: [LogisticRegression()],\n",
              "                          &#x27;classifier__C&#x27;: array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
              "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
              "       3.59381366e+03, 1.00000000e+04]),\n",
              "                          &#x27;classifier__max_iter&#x27;: [100, 150, 2...\n",
              "                          &#x27;classifier__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,\n",
              "                                                 &#x27;liblinear&#x27;],\n",
              "                          &#x27;classifier__verbose&#x27;: [2]},\n",
              "                         {&#x27;classifier&#x27;: [RandomForestClassifier()],\n",
              "                          &#x27;classifier__bootstrap&#x27;: [True, False],\n",
              "                          &#x27;classifier__max_depth&#x27;: [1, 5, 10],\n",
              "                          &#x27;classifier__max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
              "                          &#x27;classifier__min_samples_leaf&#x27;: [1, 2, 5],\n",
              "                          &#x27;classifier__min_samples_split&#x27;: [2, 5, 10],\n",
              "                          &#x27;classifier__n_estimators&#x27;: [10, 100, 1000]}],\n",
              "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gridSearch.cv_results_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hijDWDrqv3P2",
        "outputId": "2b6afd46-e4d1-4dd9-a5c3-5a7861d06ba8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([2.16562748e-03, 1.81069374e-03, 8.67334385e+00, 2.36173749e-01,\n",
              "        2.68095326e-01, 1.93827057e-01, 1.99034214e-03, 2.63361931e-03,\n",
              "        2.76212692e-03, 1.58374310e-03, 1.85594559e-03, 9.06272242e+00,\n",
              "        1.78633356e-01, 2.70433760e-01, 1.44073486e-01, 1.64074898e-03,\n",
              "        1.41236782e-03, 1.73051357e-03, 1.62096024e-03, 3.29775810e-03,\n",
              "        8.52615359e+00, 2.69113660e-01, 4.84218597e-01, 1.50224614e-01,\n",
              "        4.76715565e-03, 3.47735882e-03, 3.76615524e-03, 4.08084393e-03,\n",
              "        2.82871723e-03, 8.84449809e+00, 1.55045485e-01, 6.20481730e-01,\n",
              "        1.77392507e-01, 1.79901123e-03, 3.04486752e-03, 2.77574062e-03,\n",
              "        1.38525963e-03, 4.29730415e-03, 1.02875977e+01, 2.43614888e-01,\n",
              "        1.74202013e-01, 1.53060961e-01, 3.61285210e-03, 3.70190144e-03,\n",
              "        2.54418850e-03, 2.30183601e-03, 3.30102444e-03, 1.11950186e+01,\n",
              "        2.24417090e-01, 2.62004089e-01, 1.77012777e-01, 4.03347015e-03,\n",
              "        3.13367844e-03, 3.73022556e-03, 3.03025246e-03, 2.06656456e-03,\n",
              "        1.07061774e+01, 2.93300939e-01, 4.70571136e-01, 2.88498735e-01,\n",
              "        2.30121613e-03, 4.02927399e-03, 5.64568043e-03, 1.70794249e-02,\n",
              "        8.26029778e-03, 1.06885548e+01, 2.09515381e-01, 6.42160130e-01,\n",
              "        2.68459702e-01, 3.78966331e-03, 4.93731499e-03, 4.73127365e-03,\n",
              "        3.57046127e-03, 3.74591351e-03, 1.05293301e+01, 4.39927149e-01,\n",
              "        2.42489409e-01, 2.47470999e-01, 6.01251125e-03, 5.69036007e-03,\n",
              "        4.06441689e-03, 2.89282799e-03, 4.27429676e-03, 1.06522464e+01,\n",
              "        4.60906625e-01, 2.83459258e-01, 2.09228992e-01, 1.61314011e-03,\n",
              "        1.99501514e-03, 1.60593987e-03, 1.92663670e-03, 1.44717693e-03,\n",
              "        1.08802057e+01, 4.39564919e-01, 3.70986986e-01, 2.28183103e-01,\n",
              "        2.95681953e-03, 2.50244141e-03, 2.26764679e-03, 3.24041843e-03,\n",
              "        1.78539753e-03, 1.07015296e+01, 2.48724890e-01, 5.36179328e-01,\n",
              "        3.14071417e-01, 1.85842514e-03, 4.53741550e-03, 3.53679657e-03,\n",
              "        4.27980423e-03, 4.19342518e-03, 1.07869451e+01, 4.09662318e-01,\n",
              "        2.13493371e-01, 1.99287724e-01, 1.46343708e-03, 1.48241520e-03,\n",
              "        1.45533085e-03, 1.44889355e-03, 1.65536404e-03, 1.11899312e+01,\n",
              "        4.84664726e-01, 3.51032495e-01, 2.53067613e-01, 3.00204754e-03,\n",
              "        2.90975571e-03, 2.42280960e-03, 2.96974182e-03, 2.99875736e-03,\n",
              "        1.13791867e+01, 4.98418117e-01, 3.62719941e-01, 2.24170780e-01,\n",
              "        2.52094269e-03, 1.57780647e-03, 1.57825947e-03, 1.56018734e-03,\n",
              "        1.93178654e-03, 1.13126615e+01, 3.07711053e-01, 6.27196121e-01,\n",
              "        3.11984015e-01, 3.98828983e-03, 5.23159504e-03, 3.37514877e-03,\n",
              "        3.37474346e-03, 2.94799805e-03, 1.05591419e+01, 3.38627243e-01,\n",
              "        1.70061016e-01, 4.25886369e-01, 1.70485973e-03, 1.59435272e-03,\n",
              "        1.81765556e-03, 1.57048702e-03, 1.68671608e-03, 1.12771255e+01,\n",
              "        4.55393028e-01, 2.32917666e-01, 2.86043453e-01, 2.24361420e-03,\n",
              "        2.18336582e-03, 3.56955528e-03, 1.78549290e-03, 5.07397652e-03,\n",
              "        1.17082044e+01, 4.71006703e-01, 3.61169839e-01, 3.00094724e-01,\n",
              "        1.43947601e-03, 1.38232708e-03, 1.43597126e-03, 1.40669346e-03,\n",
              "        1.63102150e-03, 1.10740345e+01, 5.48192573e-01, 6.25285792e-01,\n",
              "        2.96296692e-01, 2.57999897e-03, 1.60055161e-03, 1.47807598e-03,\n",
              "        1.46665573e-03, 1.45761967e-03, 1.11769533e+01, 6.31047249e-01,\n",
              "        1.80415606e-01, 2.67112279e-01, 1.43561363e-03, 1.71802044e-03,\n",
              "        1.41673088e-03, 1.38435364e-03, 1.71585083e-03, 1.11352706e+01,\n",
              "        6.42877293e-01, 2.63542700e-01, 3.07579303e-01, 2.33500004e-03,\n",
              "        1.91080570e-03, 2.01230049e-03, 2.14042664e-03, 1.83432102e-03,\n",
              "        1.15914226e+01, 6.30883026e-01, 3.85674739e-01, 2.70013022e-01,\n",
              "        1.45883560e-03, 1.52995586e-03, 1.43523216e-03, 1.43558979e-03,\n",
              "        1.70078278e-03, 1.17007657e+01, 3.74676037e-01, 6.07247019e-01,\n",
              "        3.86045313e-01, 2.32198238e-03, 2.51710415e-03, 2.56812572e-03,\n",
              "        2.85062790e-03, 2.46706009e-03, 1.14061587e+01, 5.74131227e-01,\n",
              "        1.90177035e-01, 3.73891163e-01, 1.38409138e-03, 2.70230770e-03,\n",
              "        2.79781818e-03, 3.96683216e-03, 2.37395763e-03, 1.12955006e+01,\n",
              "        6.39154935e-01, 3.29950118e-01, 2.98617101e-01, 3.31273079e-03,\n",
              "        2.38592625e-03, 2.12914944e-03, 2.05180645e-03, 2.98736095e-03,\n",
              "        1.16704204e+01, 4.19108009e-01, 3.63774467e-01, 2.21142960e-01,\n",
              "        1.49352551e-03, 1.66969299e-03, 1.77307129e-03, 1.81367397e-03,\n",
              "        1.86045170e-03, 1.15689398e+01, 4.19344640e-01, 6.22326183e-01,\n",
              "        3.16640067e-01, 2.01721191e-03, 2.11014748e-03, 4.33211327e-03,\n",
              "        5.08275032e-03, 4.37297821e-03, 1.07257608e+01, 4.29298711e-01,\n",
              "        2.03636861e-01, 4.06715345e-01, 2.06344128e-03, 3.58896255e-03,\n",
              "        2.91521549e-03, 2.66916752e-03, 2.57823467e-03, 1.12042863e+01,\n",
              "        4.68830895e-01, 2.63759017e-01, 3.32423306e-01, 4.74963188e-03,\n",
              "        3.37023735e-03, 4.11305428e-03, 1.65109634e-03, 5.27589321e-03,\n",
              "        1.19680542e+01, 4.27631712e-01, 3.58495951e-01, 3.03085828e-01,\n",
              "        5.07040024e-03, 2.66330242e-03, 5.34753799e-03, 4.02317047e-03,\n",
              "        6.16118908e-03, 1.14070272e+01, 5.36302090e-01, 6.57183528e-01,\n",
              "        3.33155346e-01, 2.59394646e-03, 2.13043690e-03, 2.65104771e-03,\n",
              "        2.22635269e-03, 2.89311409e-03, 1.17504831e+01, 4.47937870e-01,\n",
              "        1.53039098e-01, 3.48867702e-01, 2.28283405e-03, 2.38530636e-03,\n",
              "        1.95543766e-03, 1.35445595e-03, 1.85072422e-03, 1.16562580e+01,\n",
              "        4.45907640e-01, 2.96844792e-01, 4.44163108e-01, 2.13692188e-03,\n",
              "        1.70187950e-03, 1.88908577e-03, 2.39276886e-03, 3.75461578e-03,\n",
              "        1.12330620e+01, 6.82563567e-01, 3.43474674e-01, 3.61870766e-01,\n",
              "        1.81436539e-03, 1.57108307e-03, 1.43995285e-03, 1.41885281e-03,\n",
              "        2.27360725e-03, 1.14913300e+01, 7.41770267e-01, 5.69854331e-01,\n",
              "        3.30815792e-01, 1.77366734e-03, 1.66897774e-03, 1.58348083e-03,\n",
              "        1.50940418e-03, 1.44979954e-03, 1.09998754e+01, 4.59730792e-01,\n",
              "        1.74388337e-01, 2.46032357e-01, 1.65457726e-03, 1.66769028e-03,\n",
              "        1.77290440e-03, 1.67543888e-03, 2.37417221e-03, 1.16754383e+01,\n",
              "        5.11683559e-01, 2.68612194e-01, 3.35896611e-01, 3.36639881e-03,\n",
              "        4.74593639e-03, 4.68797684e-03, 2.76973248e-03, 4.34117317e-03,\n",
              "        1.17429365e+01, 4.65777159e-01, 3.68330717e-01, 3.73276496e-01,\n",
              "        2.37274170e-03, 1.60405636e-03, 1.87284946e-03, 1.52370930e-03,\n",
              "        2.42598057e-03, 1.16586465e+01, 4.60206866e-01, 5.37433791e-01,\n",
              "        4.64643550e-01, 6.23083115e-03, 4.96718884e-03, 4.92825508e-03,\n",
              "        4.11679745e-03, 4.24242020e-03, 3.85057926e-03, 4.30791378e-03,\n",
              "        5.31001091e-03, 5.20231724e-03, 2.72626877e-03, 2.64799595e-03,\n",
              "        3.76091003e-03, 4.19414043e-03, 3.28307152e-03, 3.09216976e-03,\n",
              "        4.19390202e-03, 2.95822620e-03, 2.33731270e-03, 2.97369957e-03,\n",
              "        2.29973793e-03, 3.14569473e-03, 2.30419636e-03, 1.35743618e-03,\n",
              "        1.81269646e-03, 2.53782272e-03, 4.85799313e-03, 3.00567150e-03,\n",
              "        3.48086357e-03, 3.31394672e-03, 2.69482136e-03, 8.34254503e-02,\n",
              "        3.95692778e-01, 4.09108341e+00, 6.17954016e-02, 4.09878516e-01,\n",
              "        4.30416257e+00, 3.98096085e-02, 4.91055512e-01, 4.04817493e+00,\n",
              "        3.95545244e-02, 4.40679312e-01, 4.34869680e+00, 3.82596254e-02,\n",
              "        4.10442972e-01, 4.15849524e+00, 3.99850845e-02, 3.89851880e-01,\n",
              "        4.27533119e+00, 6.44349813e-02, 5.45546913e-01, 4.06478386e+00,\n",
              "        4.00886536e-02, 3.49194145e-01, 4.19562078e+00, 6.88446999e-02,\n",
              "        6.41208649e-01, 4.12948744e+00, 4.09847260e-02, 3.51981950e-01,\n",
              "        3.99589729e+00, 5.68501949e-02, 6.13836384e-01, 4.32882771e+00,\n",
              "        4.04382706e-02, 3.53893852e-01, 4.07233291e+00, 4.03665304e-02,\n",
              "        5.40378499e-01, 4.43088977e+00, 3.96905899e-02, 3.50494289e-01,\n",
              "        4.03835559e+00, 3.93086195e-02, 3.49719977e-01, 4.60215507e+00,\n",
              "        5.21787167e-02, 3.50948143e-01, 4.04131215e+00, 3.98958206e-02,\n",
              "        3.51394343e-01, 4.47571325e+00, 8.00888538e-02, 4.35138607e-01,\n",
              "        4.05104117e+00, 1.67999268e-03, 1.53276920e-03, 1.79283619e-03,\n",
              "        1.78849697e-03, 1.46069527e-03, 1.41658783e-03, 2.08659172e-03,\n",
              "        1.43365860e-03, 1.69405937e-03, 1.51610374e-03, 2.71151066e-03,\n",
              "        1.35710239e-03, 2.47735977e-03, 2.41479874e-03, 1.69570446e-03,\n",
              "        2.80876160e-03, 1.36847496e-03, 1.45807266e-03, 3.33876610e-03,\n",
              "        2.13165283e-03, 1.39565468e-03, 1.51388645e-03, 1.44381523e-03,\n",
              "        1.39098167e-03, 3.14111710e-03, 2.60236263e-03, 2.71854401e-03,\n",
              "        4.83908415e-02, 5.19527674e-01, 5.42006700e+00, 4.90764856e-02,\n",
              "        4.36626458e-01, 5.28374705e+00, 4.93963480e-02, 5.27393866e-01,\n",
              "        5.43018205e+00, 5.10495663e-02, 4.38439655e-01, 5.23294597e+00,\n",
              "        6.44603014e-02, 6.93062329e-01, 5.20519845e+00, 4.71358776e-02,\n",
              "        4.34444356e-01, 5.57896504e+00, 5.09486914e-02, 7.14810181e-01,\n",
              "        5.24422436e+00, 4.87455368e-02, 4.53696609e-01, 5.48785346e+00,\n",
              "        5.20679235e-02, 4.44397235e-01, 5.34126506e+00, 1.01134777e-01,\n",
              "        6.14141440e-01, 4.99286492e+00, 9.34400797e-02, 7.93387675e-01,\n",
              "        5.38656650e+00, 5.48456430e-02, 7.66627407e-01, 5.20235727e+00,\n",
              "        5.25810242e-02, 4.53403568e-01, 5.75244572e+00, 4.87185240e-02,\n",
              "        4.46647906e-01, 5.52806506e+00, 4.95181084e-02, 4.49147964e-01,\n",
              "        5.63899436e+00, 5.07449150e-02, 4.40239978e-01, 5.58659050e+00,\n",
              "        5.02732515e-02, 4.37682128e-01, 5.21864700e+00, 8.59145403e-02,\n",
              "        6.68865466e-01, 4.95801201e+00, 1.67031288e-03, 1.50399208e-03,\n",
              "        1.45947933e-03, 1.45492554e-03, 1.40404701e-03, 1.82273388e-03,\n",
              "        1.43435001e-03, 3.03964615e-03, 2.68111229e-03, 2.40492821e-03,\n",
              "        4.92231846e-03, 4.28316593e-03, 1.96888447e-03, 1.55754089e-03,\n",
              "        3.50842476e-03, 1.59127712e-03, 1.36053562e-03, 2.81496048e-03,\n",
              "        2.61309147e-03, 4.01906967e-03, 3.07018757e-03, 2.48157978e-03,\n",
              "        3.75638008e-03, 3.28946114e-03, 1.85921192e-03, 4.21621799e-03,\n",
              "        3.91454697e-03, 1.05821609e-01, 6.97886324e-01, 5.46005673e+00,\n",
              "        5.03442049e-02, 6.59541655e-01, 5.60629876e+00, 7.81420231e-02,\n",
              "        7.04767776e-01, 5.50130918e+00, 5.32794714e-02, 6.60858083e-01,\n",
              "        5.53083069e+00, 5.10818481e-02, 4.66348863e-01, 5.69286742e+00,\n",
              "        5.04628181e-02, 4.60201764e-01, 5.68729217e+00, 7.84020662e-02,\n",
              "        4.54882669e-01, 5.69365954e+00, 5.17247200e-02, 4.54913449e-01,\n",
              "        5.62799335e+00, 8.72741699e-02, 5.29094315e-01, 5.55046008e+00,\n",
              "        1.07318830e-01, 6.27224445e-01, 5.36922388e+00, 9.28711891e-02,\n",
              "        7.40621185e-01, 5.24381883e+00, 9.19724464e-02, 8.59276915e-01,\n",
              "        5.22590122e+00, 7.11909533e-02, 8.07010269e-01, 5.27519662e+00,\n",
              "        5.62991858e-02, 7.19515777e-01, 5.49199684e+00, 5.29650211e-02,\n",
              "        5.86802006e-01, 5.46184211e+00, 5.00952005e-02, 4.69161344e-01,\n",
              "        5.76658916e+00, 5.03444195e-02, 4.73548079e-01, 5.71827910e+00,\n",
              "        6.19579554e-02, 4.66073489e-01, 5.76977458e+00, 1.65154934e-03,\n",
              "        1.63280964e-03, 1.84876919e-03, 2.00147629e-03, 1.54016018e-03,\n",
              "        1.79877281e-03, 1.61750317e-03, 1.62377357e-03, 1.41909122e-03,\n",
              "        2.30417252e-03, 2.44314671e-03, 1.58791542e-03, 1.46825314e-03,\n",
              "        2.27513313e-03, 1.99971199e-03, 1.39205456e-03, 1.40619278e-03,\n",
              "        1.90868378e-03, 1.40440464e-03, 1.36337280e-03, 2.06131935e-03,\n",
              "        2.57835388e-03, 2.44264603e-03, 1.42343044e-03, 1.35838985e-03,\n",
              "        1.35633945e-03, 2.01363564e-03, 3.82536888e-02, 2.83934069e-01,\n",
              "        3.30099838e+00, 6.10069036e-02, 5.19990230e-01, 3.36352422e+00,\n",
              "        3.47550392e-02, 2.71835423e-01, 3.29408309e+00, 3.77003193e-02,\n",
              "        4.61634064e-01, 3.38129740e+00, 3.42796087e-02, 3.56936717e-01,\n",
              "        3.47423429e+00, 3.24716806e-02, 3.10607243e-01, 3.37846663e+00,\n",
              "        5.24725914e-02, 3.37488055e-01, 3.43810003e+00, 3.33085299e-02,\n",
              "        2.80186105e-01, 3.34432580e+00, 4.90422010e-02, 5.11584854e-01,\n",
              "        3.33330185e+00, 5.89176178e-02, 2.76018858e-01, 3.31686804e+00,\n",
              "        3.29927683e-02, 2.82219172e-01, 3.34647257e+00, 3.50618839e-02,\n",
              "        2.77046013e-01, 3.27301776e+00, 3.57336283e-02, 2.87445283e-01,\n",
              "        3.31859248e+00, 3.35289478e-02, 3.40845418e-01, 3.44825537e+00,\n",
              "        5.41929722e-02, 4.68495488e-01, 3.40325270e+00, 3.78889084e-02,\n",
              "        2.89999890e-01, 3.24323015e+00, 3.15118551e-02, 2.84239292e-01,\n",
              "        3.33393812e+00, 3.53023529e-02, 2.76562285e-01, 3.29077222e+00,\n",
              "        1.94666386e-03, 1.60138607e-03, 1.59354210e-03, 1.45702362e-03,\n",
              "        1.41911507e-03, 1.37593746e-03, 1.51600838e-03, 1.39009953e-03,\n",
              "        1.31819248e-03, 1.71935558e-03, 2.23660469e-03, 1.39546394e-03,\n",
              "        3.27625275e-03, 1.40867233e-03, 1.45559311e-03, 1.38502121e-03,\n",
              "        1.41253471e-03, 3.03139687e-03, 2.72886753e-03, 3.94284725e-03,\n",
              "        1.52122974e-03, 1.38192177e-03, 1.36871338e-03, 1.40531063e-03,\n",
              "        1.93078518e-03, 1.39427185e-03, 2.10995674e-03, 5.15557766e-02,\n",
              "        5.58188939e-01, 5.13247898e+00, 4.61325645e-02, 4.27247405e-01,\n",
              "        5.02239792e+00, 4.63225842e-02, 5.76930547e-01, 5.14795661e+00,\n",
              "        4.79641199e-02, 4.19380403e-01, 5.00380442e+00, 4.59990025e-02,\n",
              "        4.91673231e-01, 5.06716392e+00, 8.51947546e-02, 5.18475795e-01,\n",
              "        4.98160117e+00, 4.52697039e-02, 4.84349275e-01, 5.09618597e+00,\n",
              "        8.70621920e-02, 5.05585837e-01, 5.00108848e+00, 4.51009512e-02,\n",
              "        4.17255569e-01, 5.12453790e+00, 4.68791246e-02, 4.15048122e-01,\n",
              "        5.02662747e+00, 9.40480947e-02, 5.81891394e-01, 4.70824928e+00,\n",
              "        4.53879833e-02, 6.36529589e-01, 5.02535546e+00, 4.80923176e-02,\n",
              "        4.19545484e-01, 5.30066071e+00, 4.87427235e-02, 4.20883918e-01,\n",
              "        5.00229697e+00, 8.30093622e-02, 6.99893689e-01, 4.71435907e+00,\n",
              "        4.93158102e-02, 4.91014767e-01, 5.19480400e+00, 4.63215828e-02,\n",
              "        4.13294578e-01, 5.13896058e+00, 4.62414026e-02, 4.19575071e-01,\n",
              "        4.82469091e+00, 4.21001911e-03, 3.96566391e-03, 2.39987373e-03,\n",
              "        2.86471844e-03, 3.35931778e-03, 3.06334496e-03, 1.81808472e-03,\n",
              "        1.38757229e-03, 2.00774670e-03, 3.84378433e-03, 2.35881805e-03,\n",
              "        2.11794376e-03, 1.41253471e-03, 4.95872498e-03, 5.06792068e-03,\n",
              "        2.15988159e-03, 2.30844021e-03, 2.10416317e-03, 3.53667736e-03,\n",
              "        3.15907001e-03, 4.59394455e-03, 2.14405060e-03, 1.33779049e-03,\n",
              "        2.59437561e-03, 4.60989475e-03, 3.37290764e-03, 3.01966667e-03,\n",
              "        8.24509144e-02, 6.06498647e-01, 5.26970563e+00, 7.97183514e-02,\n",
              "        6.02495527e-01, 5.29883404e+00, 4.98988628e-02, 6.12529373e-01,\n",
              "        5.46783922e+00, 5.12338161e-02, 6.25185823e-01, 5.41330020e+00,\n",
              "        4.92914438e-02, 4.42825818e-01, 5.45318179e+00, 5.09130478e-02,\n",
              "        4.48823166e-01, 5.51350231e+00, 7.15509653e-02, 4.46384144e-01,\n",
              "        5.20145366e+00, 7.86764860e-02, 7.28300285e-01, 5.08500085e+00,\n",
              "        1.01481128e-01, 7.64306307e-01, 5.12789829e+00, 5.21188974e-02,\n",
              "        6.28361368e-01, 5.40913417e+00, 4.90084410e-02, 4.48462033e-01,\n",
              "        5.62802007e+00, 4.87810612e-02, 4.45288157e-01, 5.50946503e+00,\n",
              "        5.03058672e-02, 4.43195343e-01, 5.64482093e+00, 5.22699833e-02,\n",
              "        4.53788447e-01, 6.24330039e+00, 9.50469732e-02, 4.48743224e-01,\n",
              "        5.23821938e+00, 8.90096664e-02, 6.99266195e-01, 5.07400308e+00,\n",
              "        9.06471014e-02, 7.39198089e-01, 5.24254925e+00, 5.09811878e-02,\n",
              "        5.39748812e-01, 5.47943301e+00]),\n",
              " 'std_fit_time': array([7.23993016e-04, 1.51344433e-04, 2.90886966e+00, 4.78364116e-02,\n",
              "        3.21458993e-02, 5.58013165e-02, 3.13501583e-04, 1.64250434e-03,\n",
              "        1.43652526e-03, 1.65985366e-04, 8.93457560e-04, 3.06307370e+00,\n",
              "        4.63279168e-02, 4.78157613e-02, 2.37442170e-02, 2.00580342e-04,\n",
              "        1.32824933e-04, 3.12088974e-04, 6.80596142e-05, 2.76237653e-03,\n",
              "        2.85270175e+00, 2.79740705e-02, 5.63159442e-02, 1.81355059e-02,\n",
              "        3.12214939e-03, 3.80634189e-04, 1.90189747e-03, 2.59778466e-03,\n",
              "        3.61431042e-04, 2.91707068e+00, 1.38230048e-02, 1.39971475e-01,\n",
              "        4.69649713e-02, 8.01048953e-04, 8.21397794e-04, 1.65031586e-03,\n",
              "        5.68617865e-05, 1.47190362e-03, 1.42281266e+00, 4.06891771e-02,\n",
              "        4.07056275e-02, 4.45629493e-02, 1.77274690e-03, 1.73970569e-03,\n",
              "        1.09442063e-03, 1.58099480e-03, 6.23400808e-04, 1.66182425e+00,\n",
              "        1.27701074e-02, 4.92532363e-02, 3.28969231e-02, 3.85782749e-03,\n",
              "        2.21956630e-03, 2.75914026e-03, 1.66442851e-03, 4.90137431e-04,\n",
              "        1.59758845e+00, 1.06335814e-01, 1.16131261e-01, 1.41801430e-01,\n",
              "        5.16932783e-04, 1.56744812e-03, 3.92581190e-03, 1.08415449e-02,\n",
              "        3.59872046e-03, 1.57481640e+00, 1.21853886e-02, 1.28160709e-01,\n",
              "        5.06140006e-02, 1.84050304e-03, 1.76859833e-03, 2.09621746e-03,\n",
              "        2.01198229e-03, 2.04876743e-03, 1.22708401e+00, 7.49028270e-02,\n",
              "        5.51890334e-02, 7.09631199e-02, 3.74417975e-03, 1.64093230e-03,\n",
              "        2.87426745e-03, 1.72301706e-03, 4.00729846e-03, 1.05391270e+00,\n",
              "        7.51057370e-02, 6.81770253e-02, 4.66228351e-02, 8.73565153e-05,\n",
              "        4.17420114e-04, 1.51058700e-04, 1.08864565e-03, 1.15485611e-04,\n",
              "        1.27397489e+00, 9.39070909e-02, 8.14582878e-02, 1.63628709e-02,\n",
              "        7.82365246e-04, 3.61339761e-04, 3.40337119e-04, 1.93715519e-03,\n",
              "        4.24688092e-04, 1.32532559e+00, 1.36876412e-02, 1.25194048e-01,\n",
              "        5.48698669e-02, 1.50898462e-04, 2.01200304e-03, 2.11501920e-03,\n",
              "        2.49239842e-03, 1.59810146e-03, 1.72541305e+00, 1.21290745e-01,\n",
              "        4.77920015e-02, 5.07235938e-02, 7.63919655e-05, 1.57746498e-04,\n",
              "        1.26889828e-04, 1.21287702e-04, 3.19998103e-04, 1.26334623e+00,\n",
              "        1.00714042e-01, 4.73750634e-02, 6.09438588e-02, 7.16039889e-04,\n",
              "        1.37631544e-03, 7.75201348e-04, 1.74045276e-03, 1.18792202e-03,\n",
              "        1.68956209e+00, 1.11415424e-01, 8.92809388e-02, 6.59780108e-02,\n",
              "        4.20845697e-04, 7.50629991e-05, 1.69927130e-04, 3.05018039e-04,\n",
              "        1.47911099e-04, 9.62763116e-01, 2.46459590e-02, 1.07269241e-01,\n",
              "        1.14874495e-01, 3.36335536e-03, 3.05944221e-03, 1.45647543e-03,\n",
              "        1.44913169e-03, 1.25316608e-03, 1.74200609e+00, 2.37881721e-02,\n",
              "        4.97506722e-02, 9.77386007e-02, 5.55629371e-04, 1.67651049e-04,\n",
              "        4.34367792e-04, 7.83675341e-05, 1.73882552e-04, 7.85787403e-01,\n",
              "        1.23641964e-01, 6.05470205e-02, 9.54142621e-02, 4.73494571e-04,\n",
              "        4.79278633e-04, 2.29612868e-03, 3.68259927e-04, 3.12095289e-03,\n",
              "        9.72776134e-01, 1.60366406e-01, 7.74362539e-02, 8.25466704e-02,\n",
              "        9.77475003e-05, 2.52486176e-05, 9.59818508e-05, 6.70034643e-05,\n",
              "        1.10544080e-04, 1.25495789e+00, 1.13517795e-01, 9.25159096e-02,\n",
              "        8.88110878e-02, 6.10189938e-04, 1.47854001e-04, 1.47262618e-04,\n",
              "        1.24172608e-04, 1.05990778e-04, 1.34642474e+00, 1.20187544e-01,\n",
              "        4.75301341e-02, 8.57627132e-02, 9.69211963e-05, 9.04681995e-04,\n",
              "        7.16780627e-05, 3.17713131e-05, 2.09567729e-04, 1.58023700e+00,\n",
              "        1.01252183e-01, 7.69383801e-02, 6.75737808e-02, 7.98400424e-04,\n",
              "        4.31903416e-04, 1.22151259e-03, 1.71082727e-03, 1.07148355e-03,\n",
              "        9.96437615e-01, 8.31125884e-02, 6.34152844e-02, 8.77141550e-02,\n",
              "        9.21134616e-05, 1.28695754e-04, 9.41468932e-05, 6.08121675e-05,\n",
              "        2.16642534e-04, 1.29411030e+00, 2.89851122e-02, 1.47637708e-01,\n",
              "        1.47176778e-01, 4.91000433e-04, 8.46238306e-04, 1.19773522e-03,\n",
              "        1.90073395e-03, 1.71654906e-03, 1.38050766e+00, 1.97362076e-01,\n",
              "        4.47606846e-02, 1.56311802e-01, 1.08769266e-04, 3.10468622e-03,\n",
              "        3.09291238e-03, 3.60236407e-03, 1.52478659e-03, 8.62909106e-01,\n",
              "        1.51538309e-01, 4.15630885e-02, 9.41424096e-02, 1.00887715e-03,\n",
              "        5.04275428e-04, 3.24735103e-04, 4.28766731e-04, 1.74816000e-03,\n",
              "        1.29148453e+00, 3.23320746e-02, 9.10483350e-02, 3.29176566e-02,\n",
              "        8.79672835e-05, 1.37162637e-04, 3.82081715e-04, 6.64354279e-04,\n",
              "        7.64813328e-04, 1.23745416e+00, 3.07070480e-02, 1.73611670e-01,\n",
              "        9.15367782e-02, 1.01969472e-04, 5.53718465e-04, 1.90903499e-03,\n",
              "        3.47196968e-03, 3.13917042e-03, 1.38546247e+00, 3.67439037e-02,\n",
              "        4.67224270e-02, 8.23242073e-02, 1.53724178e-03, 3.23509749e-03,\n",
              "        2.85327439e-03, 2.51171445e-03, 1.69211810e-03, 9.55340361e-01,\n",
              "        9.57362443e-02, 4.26597331e-02, 1.19623848e-01, 2.82957972e-03,\n",
              "        1.20603819e-03, 1.50151196e-03, 2.04728794e-04, 4.04178327e-03,\n",
              "        9.36545362e-01, 4.98897846e-02, 7.81742510e-02, 1.41254558e-01,\n",
              "        2.64988437e-03, 1.58351101e-03, 2.51544050e-03, 2.02563409e-03,\n",
              "        2.25130983e-03, 7.65804646e-01, 1.45431668e-01, 1.02677435e-01,\n",
              "        1.29862253e-01, 7.62471203e-04, 4.01400744e-04, 2.33741971e-03,\n",
              "        7.56549668e-04, 1.39176079e-03, 1.63995379e+00, 3.32802319e-02,\n",
              "        3.96731018e-02, 8.42505255e-02, 1.18396062e-03, 1.89832307e-03,\n",
              "        7.95663162e-04, 5.63577345e-05, 9.55692512e-04, 8.98432991e-01,\n",
              "        4.33839243e-02, 5.34673831e-02, 1.46304550e-01, 1.12312931e-03,\n",
              "        1.55489235e-04, 8.08313383e-04, 2.13506911e-03, 3.23766759e-03,\n",
              "        1.04233193e+00, 1.26519936e-01, 6.42268855e-02, 9.80734905e-02,\n",
              "        1.09933022e-03, 2.18826339e-04, 1.07141192e-04, 2.72310028e-05,\n",
              "        8.84890958e-04, 1.03643535e+00, 1.74891182e-01, 1.24093279e-01,\n",
              "        5.94343312e-02, 6.13989688e-05, 1.48028941e-04, 1.70281620e-04,\n",
              "        1.56008535e-04, 1.21287796e-04, 2.55967360e+00, 5.94398665e-02,\n",
              "        3.87755604e-02, 2.89161308e-02, 1.39438461e-04, 2.31149679e-04,\n",
              "        5.29632762e-04, 2.18053494e-04, 9.75510214e-04, 1.22582443e+00,\n",
              "        9.33104919e-02, 5.39630241e-02, 1.13561721e-01, 1.36455619e-03,\n",
              "        2.38518848e-03, 3.07299482e-03, 1.19587446e-03, 2.16210682e-03,\n",
              "        1.05158790e+00, 5.73860409e-02, 9.01273918e-02, 1.40757218e-01,\n",
              "        9.77709612e-04, 2.33893692e-04, 3.82528505e-04, 7.38308431e-05,\n",
              "        7.75581692e-04, 1.01564096e+00, 5.86978612e-02, 1.27368246e-01,\n",
              "        1.72547809e-01, 4.26570530e-03, 3.98730408e-03, 2.70264543e-03,\n",
              "        1.89907478e-03, 2.76860716e-03, 2.81690461e-03, 3.20122301e-03,\n",
              "        1.92513661e-03, 2.75425045e-03, 1.11551730e-03, 1.56739800e-03,\n",
              "        1.91443137e-03, 1.29811438e-03, 2.33689162e-03, 1.71204224e-03,\n",
              "        2.85154426e-03, 2.68644331e-03, 1.24170160e-03, 2.23172899e-03,\n",
              "        1.22658531e-03, 2.82026273e-03, 1.75881783e-03, 8.47740332e-05,\n",
              "        7.29670477e-04, 2.83243388e-03, 4.21137447e-03, 2.60054688e-03,\n",
              "        3.28959146e-03, 3.78524950e-03, 2.53719502e-03, 1.51753067e-02,\n",
              "        1.16320016e-01, 1.04184161e+00, 1.73268727e-02, 1.06927265e-01,\n",
              "        1.07017044e+00, 1.73996802e-03, 1.52652959e-01, 8.23375726e-01,\n",
              "        1.11076628e-03, 1.43093833e-01, 7.87386719e-01, 4.88953031e-04,\n",
              "        1.29858713e-01, 8.38122060e-01, 2.70674409e-03, 8.14099654e-02,\n",
              "        1.01801918e+00, 1.44198164e-02, 1.34440546e-01, 8.08012554e-01,\n",
              "        1.50521029e-03, 8.49337880e-03, 9.91421656e-01, 1.71102473e-02,\n",
              "        9.06690174e-02, 1.10232746e+00, 1.56696379e-03, 7.10830880e-03,\n",
              "        7.63856178e-01, 1.65922920e-02, 4.61793911e-02, 7.78811163e-01,\n",
              "        1.73377324e-03, 1.11093118e-02, 7.65473573e-01, 1.15820813e-03,\n",
              "        1.18410937e-01, 8.58204906e-01, 1.33936309e-03, 9.54582599e-03,\n",
              "        1.01449425e+00, 1.16649220e-03, 7.07676184e-03, 1.17223115e+00,\n",
              "        1.80720026e-02, 1.12529184e-02, 8.04934803e-01, 1.07371973e-03,\n",
              "        1.26885859e-02, 8.61628752e-01, 3.49627553e-03, 1.30242054e-01,\n",
              "        7.33404460e-01, 3.04169359e-04, 5.05502997e-05, 9.80440111e-04,\n",
              "        7.80527149e-04, 1.49174266e-04, 1.12504733e-04, 1.85609814e-03,\n",
              "        1.25529852e-04, 8.45871609e-04, 3.19197533e-04, 2.46011160e-03,\n",
              "        4.34432999e-05, 2.87243855e-03, 2.23784010e-03, 9.25812407e-04,\n",
              "        2.41949651e-03, 2.41794057e-05, 1.89434002e-04, 4.06570583e-03,\n",
              "        2.12819333e-03, 9.47438836e-05, 4.99216909e-04, 3.20293986e-04,\n",
              "        1.00063843e-04, 3.55055799e-03, 2.50164176e-03, 2.44480601e-03,\n",
              "        1.06229419e-03, 1.20509585e-01, 1.12882556e+00, 1.52579263e-03,\n",
              "        4.88896007e-03, 1.19559618e+00, 3.85831281e-03, 1.49345103e-01,\n",
              "        1.14737069e+00, 7.80769055e-03, 1.18268650e-02, 1.23179213e+00,\n",
              "        1.38935194e-02, 1.59102096e-01, 1.30068027e+00, 8.96158466e-04,\n",
              "        1.09174487e-02, 1.42727189e+00, 4.30018677e-03, 1.58971260e-01,\n",
              "        1.30993949e+00, 3.05857561e-03, 3.34970943e-02, 1.36191456e+00,\n",
              "        8.03633918e-03, 1.79853454e-02, 8.64430357e-01, 5.14292974e-03,\n",
              "        2.10304995e-01, 1.12114666e+00, 1.56363753e-02, 7.41989474e-02,\n",
              "        9.68400185e-01, 8.68943320e-03, 8.21543566e-02, 6.97225542e-01,\n",
              "        7.49404139e-03, 4.34208392e-02, 1.39456624e+00, 1.27984098e-03,\n",
              "        1.69306210e-02, 1.19585009e+00, 1.64041418e-03, 9.21795978e-03,\n",
              "        7.83450667e-01, 7.32815846e-03, 1.07441465e-02, 1.52112336e+00,\n",
              "        4.59526429e-03, 1.00138804e-02, 7.15613733e-01, 2.10087079e-02,\n",
              "        1.77592161e-01, 1.18808243e+00, 1.07999237e-04, 4.96551897e-05,\n",
              "        9.59698160e-05, 1.30544142e-04, 1.06922054e-04, 8.40701724e-04,\n",
              "        1.42203180e-04, 2.50516630e-03, 2.19978720e-03, 1.83024522e-03,\n",
              "        4.43071298e-03, 2.95280788e-03, 1.03157530e-03, 4.90794380e-04,\n",
              "        2.59950210e-03, 7.08805404e-04, 4.95711445e-05, 2.79066318e-03,\n",
              "        2.09320285e-03, 4.11836015e-03, 2.78849296e-03, 2.27573679e-03,\n",
              "        4.21896117e-03, 4.54204064e-03, 1.04753464e-03, 8.54122427e-03,\n",
              "        3.19771229e-03, 1.29998199e-02, 1.97605086e-01, 7.98836622e-01,\n",
              "        1.20772763e-03, 1.73836617e-01, 1.20674693e+00, 2.58633390e-02,\n",
              "        1.59781591e-01, 8.54742337e-01, 8.58921296e-03, 1.63721427e-01,\n",
              "        1.02330055e+00, 1.49344887e-03, 1.56009059e-02, 1.05785007e+00,\n",
              "        1.61145041e-03, 8.38281906e-03, 8.20682037e-01, 2.33494719e-02,\n",
              "        7.43758671e-03, 1.36404723e+00, 7.67316817e-03, 1.16509371e-02,\n",
              "        7.99406587e-01, 2.07377109e-02, 1.57017033e-01, 8.23270874e-01,\n",
              "        5.26248667e-03, 2.11084071e-01, 8.75651950e-01, 1.64863243e-02,\n",
              "        1.80752673e-01, 1.14861337e+00, 1.56816107e-02, 6.87835844e-02,\n",
              "        1.09901987e+00, 2.49873677e-02, 6.83572022e-02, 8.30794731e-01,\n",
              "        9.66657555e-03, 1.49674594e-01, 8.01586274e-01, 5.83881769e-03,\n",
              "        1.82212763e-01, 7.70927965e-01, 1.63563925e-03, 2.22332985e-02,\n",
              "        1.34679719e+00, 8.79812878e-04, 2.32761641e-02, 1.42245112e+00,\n",
              "        1.45254436e-02, 8.94314549e-03, 1.34862066e+00, 8.17168298e-05,\n",
              "        4.04664884e-05, 7.81583639e-04, 1.19913803e-03, 3.40706664e-04,\n",
              "        1.04539238e-03, 2.74109023e-04, 2.67273761e-04, 5.22734515e-05,\n",
              "        2.49297354e-03, 3.12027657e-03, 3.37505256e-04, 9.27827612e-05,\n",
              "        2.20623277e-03, 1.51150243e-03, 5.42325549e-05, 5.14100341e-05,\n",
              "        1.01038670e-03, 3.71670401e-05, 5.74494983e-05, 1.84038757e-03,\n",
              "        3.38617107e-03, 2.08169198e-03, 1.50463283e-04, 2.57240831e-05,\n",
              "        2.20370100e-05, 1.89068503e-03, 1.11434944e-02, 1.14927244e-02,\n",
              "        7.07164853e-01, 4.57974156e-02, 3.38918539e-02, 7.60459472e-01,\n",
              "        6.05508473e-03, 4.40909473e-03, 7.30918481e-01, 1.16681823e-02,\n",
              "        6.03687803e-02, 7.84854265e-01, 6.79116342e-03, 1.21457264e-01,\n",
              "        7.54162498e-01, 1.43992912e-03, 7.68827944e-02, 8.33461639e-01,\n",
              "        1.50476340e-02, 9.43574741e-02, 8.34221972e-01, 3.68161592e-03,\n",
              "        9.92429592e-03, 6.97202880e-01, 1.48416841e-02, 5.41583996e-02,\n",
              "        7.02102196e-01, 6.53257827e-03, 4.05933228e-03, 7.83309555e-01,\n",
              "        1.81271688e-03, 8.05180480e-03, 7.53756249e-01, 4.72036127e-03,\n",
              "        6.27069296e-03, 7.06893999e-01, 6.30632703e-03, 1.49915012e-02,\n",
              "        8.40509138e-01, 1.20410357e-03, 8.12030626e-02, 8.55170738e-01,\n",
              "        8.94368459e-03, 5.02050977e-02, 7.53089974e-01, 1.03710571e-02,\n",
              "        1.96818360e-02, 7.62908421e-01, 3.58950633e-04, 9.24280395e-03,\n",
              "        7.61488840e-01, 5.09169187e-03, 6.27304525e-03, 6.69683454e-01,\n",
              "        7.62747043e-04, 6.22351092e-05, 1.48600882e-04, 2.09202591e-04,\n",
              "        1.07669830e-04, 7.89337953e-05, 1.95403777e-04, 1.28104157e-04,\n",
              "        1.63411371e-05, 7.36942080e-04, 2.57400432e-03, 8.37156180e-05,\n",
              "        4.78580577e-03, 6.90508282e-05, 1.99064288e-04, 5.32859710e-05,\n",
              "        8.90582085e-05, 2.69134869e-03, 2.48326469e-03, 3.27572849e-03,\n",
              "        2.49135580e-04, 3.54082976e-05, 6.69867791e-05, 7.90368234e-05,\n",
              "        1.50459437e-03, 5.91657694e-05, 2.22701504e-03, 1.40807444e-02,\n",
              "        1.28424258e-01, 1.10318615e+00, 1.72742644e-03, 2.24269374e-02,\n",
              "        9.87799570e-01, 1.54858878e-03, 1.55020881e-01, 1.17501233e+00,\n",
              "        7.38242506e-03, 2.08102478e-02, 9.86812856e-01, 1.49912024e-03,\n",
              "        1.31851059e-01, 1.03765541e+00, 1.06106650e-02, 1.66190498e-01,\n",
              "        9.77433702e-01, 7.15606655e-04, 1.03204730e-01, 1.19307455e+00,\n",
              "        1.54756028e-02, 1.68443408e-01, 1.00745356e+00, 1.68029428e-03,\n",
              "        9.41835265e-03, 5.64649501e-01, 2.14417421e-03, 1.05138662e-02,\n",
              "        9.90750759e-01, 9.67430738e-03, 1.99410147e-01, 1.17205282e+00,\n",
              "        1.26598002e-03, 1.32426492e-01, 9.44976812e-01, 1.46752385e-03,\n",
              "        1.35386965e-02, 6.94096704e-01, 3.79431071e-03, 1.03671444e-02,\n",
              "        7.88271507e-01, 1.06728354e-02, 1.76831549e-01, 9.90925442e-01,\n",
              "        5.22448444e-03, 1.16795039e-01, 1.30555818e+00, 1.70971281e-03,\n",
              "        9.33739369e-03, 8.05710800e-01, 2.17040989e-03, 7.87672262e-03,\n",
              "        6.82382172e-01, 3.86554697e-03, 2.12974696e-03, 1.86475113e-03,\n",
              "        2.84068439e-03, 2.79161054e-03, 4.72914393e-03, 1.32715299e-03,\n",
              "        1.20629079e-04, 1.50273220e-03, 3.18155074e-03, 1.34152863e-03,\n",
              "        2.29829114e-03, 1.79795344e-04, 5.44657917e-03, 4.10275814e-03,\n",
              "        1.98645172e-03, 1.90785405e-03, 1.32208336e-03, 3.57589209e-03,\n",
              "        2.77972827e-03, 3.91365179e-03, 1.88706060e-03, 6.14018758e-05,\n",
              "        2.78943573e-03, 3.97469594e-03, 3.25820955e-03, 3.42671014e-03,\n",
              "        2.14280608e-02, 2.07020047e-01, 6.81160204e-01, 2.21180395e-02,\n",
              "        1.91608644e-01, 7.29719391e-01, 2.09567842e-03, 1.71743610e-01,\n",
              "        6.58597542e-01, 6.55194453e-03, 1.65799077e-01, 6.75092328e-01,\n",
              "        1.20156589e-03, 1.21889222e-02, 9.95978437e-01, 4.44735155e-03,\n",
              "        1.35733689e-02, 1.28770381e+00, 2.83368454e-02, 9.53743888e-03,\n",
              "        6.46247941e-01, 1.73547961e-02, 1.87101791e-01, 1.20866218e+00,\n",
              "        3.70175253e-03, 5.92913680e-02, 8.70052307e-01, 6.71592347e-03,\n",
              "        1.66300184e-01, 9.17490497e-01, 1.03099618e-03, 9.93564877e-03,\n",
              "        1.49289411e+00, 1.44196357e-03, 8.92403945e-03, 5.43269918e-01,\n",
              "        1.87799794e-03, 1.20643914e-02, 1.29726838e+00, 7.98099863e-03,\n",
              "        9.16591848e-03, 1.45180934e+00, 1.11655656e-02, 8.43462593e-03,\n",
              "        7.22492719e-01, 1.49790349e-02, 1.56398574e-01, 1.23084710e+00,\n",
              "        1.60990357e-02, 6.44212184e-02, 7.31991108e-01, 6.03940650e-03,\n",
              "        1.34579083e-01, 1.09454440e+00]),\n",
              " 'mean_score_time': array([0.        , 0.        , 0.00414772, 0.00509818, 0.00506449,\n",
              "        0.00802038, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00484395, 0.00311537, 0.00497494, 0.00514987,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00382667, 0.00397067, 0.0048233 , 0.00536566, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00363998,\n",
              "        0.00368903, 0.00487018, 0.00631351, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00460153, 0.00517421,\n",
              "        0.00670776, 0.00564783, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00734322, 0.00318644, 0.00417321,\n",
              "        0.00617399, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00372193, 0.00309763, 0.00391283, 0.0073117 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00451713, 0.00318575, 0.00412643, 0.00744071, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.0038609 ,\n",
              "        0.00373116, 0.00568829, 0.00623438, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00498989, 0.00473096,\n",
              "        0.00535576, 0.00500298, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00337079, 0.00462921, 0.00465291,\n",
              "        0.00532916, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00451245, 0.00323768, 0.0047641 , 0.00884945,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00385976, 0.00338941, 0.00499995, 0.00352852, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00333486,\n",
              "        0.00319726, 0.00479348, 0.00406814, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00490274, 0.00343719,\n",
              "        0.00415456, 0.00433769, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00389555, 0.00310602, 0.00463076,\n",
              "        0.00489125, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00386527, 0.00302095, 0.00413563, 0.00716395,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00533621, 0.00415416, 0.00422134, 0.00485518, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00354731,\n",
              "        0.00323796, 0.00472579, 0.00488815, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00457864, 0.0047822 ,\n",
              "        0.0054213 , 0.00470657, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00347657, 0.00315993, 0.00403147,\n",
              "        0.00423121, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00335095, 0.00364714, 0.0048017 , 0.00497622,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.0039989 , 0.00415447, 0.00477288, 0.00444102, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00363827,\n",
              "        0.00347099, 0.00434051, 0.00578244, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.0036381 , 0.00340462,\n",
              "        0.0035197 , 0.00590699, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00343559, 0.00390086, 0.004546  ,\n",
              "        0.00441647, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00475063, 0.00310581, 0.00424597, 0.00353267,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00316486, 0.00325785, 0.00475028, 0.00545566, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00366962,\n",
              "        0.00319588, 0.00499413, 0.00470867, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00315437, 0.00346992,\n",
              "        0.00385654, 0.00409462, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00395937, 0.00337172, 0.00435023,\n",
              "        0.00519283, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00379765, 0.00297792, 0.00493474, 0.00392561,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00354853, 0.00312972, 0.00381923, 0.00478857, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00375104,\n",
              "        0.00310781, 0.00479405, 0.00782833, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.0039475 , 0.00295801,\n",
              "        0.00460355, 0.00493894, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00319312, 0.00364847, 0.00400913,\n",
              "        0.00421247, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00402894, 0.0034935 , 0.00366397, 0.00360112,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00342064, 0.00434082, 0.00532444, 0.00527713, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00348678,\n",
              "        0.00321069, 0.00421762, 0.00485001, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00336382, 0.0030833 ,\n",
              "        0.00380461, 0.00559685, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00868156, 0.01985154, 0.1847019 ,\n",
              "        0.00601771, 0.02305858, 0.18728974, 0.00470474, 0.0248033 ,\n",
              "        0.16647804, 0.00533874, 0.0241534 , 0.18940256, 0.00462554,\n",
              "        0.02182751, 0.17670343, 0.0052742 , 0.02119055, 0.19578018,\n",
              "        0.00950327, 0.02546463, 0.1752723 , 0.00465794, 0.01892269,\n",
              "        0.19721055, 0.00829782, 0.02846382, 0.19532974, 0.00465159,\n",
              "        0.01819782, 0.18532078, 0.00675318, 0.02518559, 0.1705797 ,\n",
              "        0.00479898, 0.01792588, 0.17573698, 0.00469961, 0.02750106,\n",
              "        0.16691914, 0.0046433 , 0.01787913, 0.17917891, 0.00484176,\n",
              "        0.01904137, 0.22142954, 0.00681958, 0.01912112, 0.18403451,\n",
              "        0.00526907, 0.01798732, 0.19968147, 0.00772429, 0.02266769,\n",
              "        0.17902071, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.0050324 , 0.02461016,\n",
              "        0.21109493, 0.0050071 , 0.02084761, 0.22097962, 0.00489867,\n",
              "        0.02505138, 0.2226758 , 0.00486641, 0.02061667, 0.20017221,\n",
              "        0.00705874, 0.03178563, 0.19613943, 0.00490887, 0.02074115,\n",
              "        0.18824329, 0.00525985, 0.0312521 , 0.20710921, 0.00520923,\n",
              "        0.0233712 , 0.20451894, 0.00511932, 0.02067127, 0.2307709 ,\n",
              "        0.01277504, 0.02456386, 0.22602899, 0.00697575, 0.03328028,\n",
              "        0.20934854, 0.00497708, 0.03406901, 0.20872021, 0.00485806,\n",
              "        0.02274499, 0.18741639, 0.00497432, 0.02156191, 0.25307391,\n",
              "        0.00530567, 0.02235751, 0.23051612, 0.00531816, 0.02104139,\n",
              "        0.19413481, 0.0049643 , 0.02246299, 0.2247617 , 0.00959041,\n",
              "        0.03097014, 0.19159939, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00764375,\n",
              "        0.03044133, 0.21350198, 0.00492218, 0.03224623, 0.22913928,\n",
              "        0.00671442, 0.0323977 , 0.22539024, 0.0049696 , 0.03298492,\n",
              "        0.2362396 , 0.00522039, 0.02169583, 0.23534319, 0.00524037,\n",
              "        0.0214278 , 0.24139237, 0.00697803, 0.0220525 , 0.20884619,\n",
              "        0.0049113 , 0.02166882, 0.25442181, 0.00929   , 0.02543426,\n",
              "        0.26044288, 0.00923231, 0.02707086, 0.24096572, 0.00850289,\n",
              "        0.03122993, 0.22651808, 0.01047783, 0.03737521, 0.19589591,\n",
              "        0.00803795, 0.03677328, 0.22512934, 0.00504842, 0.03062449,\n",
              "        0.21516604, 0.00536981, 0.02762802, 0.21965835, 0.0051405 ,\n",
              "        0.02465718, 0.21495416, 0.00498652, 0.02251039, 0.20323243,\n",
              "        0.00543044, 0.02316253, 0.25256853, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00467129, 0.0180335 , 0.17799051, 0.00608375, 0.03391471,\n",
              "        0.17120647, 0.00468829, 0.01871779, 0.17167015, 0.00474203,\n",
              "        0.03245423, 0.19634573, 0.0056797 , 0.02231147, 0.17567985,\n",
              "        0.00471389, 0.02061298, 0.19597666, 0.0076405 , 0.0200623 ,\n",
              "        0.17560859, 0.00490131, 0.01812661, 0.18547032, 0.00741205,\n",
              "        0.03569665, 0.19289546, 0.00891762, 0.01980922, 0.19513714,\n",
              "        0.00481279, 0.01817889, 0.1696897 , 0.0049165 , 0.01767366,\n",
              "        0.17855771, 0.00509622, 0.01951807, 0.18433597, 0.00499475,\n",
              "        0.02116041, 0.19595566, 0.00904238, 0.03233933, 0.18284526,\n",
              "        0.00549421, 0.01914933, 0.19448009, 0.00454674, 0.01793511,\n",
              "        0.18809693, 0.00503953, 0.01951115, 0.18481095, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00513833, 0.0328305 , 0.20294993, 0.0051626 ,\n",
              "        0.02266827, 0.23040035, 0.00565894, 0.02746458, 0.21052873,\n",
              "        0.00481882, 0.02108955, 0.23033481, 0.00473335, 0.02528768,\n",
              "        0.22210245, 0.00988708, 0.02391577, 0.22904997, 0.00486505,\n",
              "        0.02384663, 0.22076316, 0.01019986, 0.02559197, 0.21825056,\n",
              "        0.00477567, 0.02025476, 0.22742023, 0.00500731, 0.02142825,\n",
              "        0.23466249, 0.01209836, 0.02870693, 0.18872948, 0.00478096,\n",
              "        0.03087165, 0.22865984, 0.00488214, 0.02114642, 0.24346042,\n",
              "        0.00588167, 0.02103505, 0.2407444 , 0.00705221, 0.03054459,\n",
              "        0.22036829, 0.00505972, 0.02578802, 0.202566  , 0.00497947,\n",
              "        0.02244105, 0.23119698, 0.00503623, 0.02059495, 0.2356318 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00611706, 0.02840643, 0.21982231,\n",
              "        0.00613356, 0.02656755, 0.23144367, 0.00502324, 0.0280354 ,\n",
              "        0.21564553, 0.00498908, 0.03049681, 0.2269717 , 0.00486164,\n",
              "        0.02112393, 0.23676665, 0.0057174 , 0.02278864, 0.2583533 ,\n",
              "        0.00492661, 0.02250211, 0.23720465, 0.00989864, 0.03218193,\n",
              "        0.23497527, 0.00956769, 0.03750393, 0.22484794, 0.00503471,\n",
              "        0.03182855, 0.22689898, 0.00495849, 0.02195542, 0.20325286,\n",
              "        0.00494537, 0.02212617, 0.24527493, 0.00491953, 0.02273271,\n",
              "        0.2331887 , 0.00537877, 0.02196701, 0.2643291 , 0.00858228,\n",
              "        0.02193749, 0.24197681, 0.0099906 , 0.02742348, 0.20820053,\n",
              "        0.00637946, 0.03601348, 0.22764721, 0.00556183, 0.02535021,\n",
              "        0.22357459]),\n",
              " 'std_score_time': array([0.00000000e+00, 0.00000000e+00, 1.67522108e-03, 3.17906972e-03,\n",
              "        1.75800502e-03, 3.68284952e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.61821336e-03,\n",
              "        1.47214690e-04, 2.18730844e-03, 1.04467897e-03, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.25599582e-03, 2.86052047e-03, 1.91068474e-03, 7.21334170e-04,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 7.97707492e-04, 9.04709182e-04, 1.52870826e-03,\n",
              "        2.36721582e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 2.30123348e-03, 4.27711152e-03,\n",
              "        3.49805293e-03, 2.07571636e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.88799265e-03,\n",
              "        1.69733984e-04, 1.33227906e-03, 2.39584559e-03, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        8.67342742e-04, 2.53012470e-04, 1.58079652e-03, 3.02679157e-03,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 3.19864918e-03, 1.88418780e-04, 1.19171135e-03,\n",
              "        2.50486127e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.31451935e-03, 1.16502780e-03,\n",
              "        1.72044388e-03, 2.01391330e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.80624870e-03,\n",
              "        3.28312256e-03, 2.13785611e-03, 1.28382794e-03, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        3.69472164e-04, 2.77664072e-03, 1.44343734e-03, 4.41716145e-04,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 2.80297049e-03, 4.60095042e-04, 1.57750289e-03,\n",
              "        4.43311808e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.71022071e-03, 9.80273932e-04,\n",
              "        1.69857818e-03, 8.29973504e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.00517230e-04,\n",
              "        4.18932802e-04, 1.33714639e-03, 8.51792482e-04, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        2.39448817e-03, 7.40804096e-04, 9.92736842e-04, 1.09936409e-03,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.21045120e-03, 2.03473131e-04, 2.15310276e-03,\n",
              "        2.94308633e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.74559527e-03, 1.43321846e-04,\n",
              "        1.00175230e-03, 2.05055252e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.67296061e-03,\n",
              "        1.79070710e-03, 2.34849812e-03, 1.50556326e-03, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        6.49027453e-04, 7.49147931e-04, 1.74112942e-03, 1.11179435e-03,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.50656564e-03, 2.41064091e-03, 2.09221764e-03,\n",
              "        1.39035364e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 4.78786119e-04, 4.91836345e-04,\n",
              "        1.52159984e-03, 1.66174677e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.23868648e-04,\n",
              "        1.41062208e-03, 1.43647265e-03, 3.37129955e-03, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.81751921e-03, 1.83445123e-03, 1.00338285e-03, 1.36732824e-03,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.13128179e-03, 9.92754380e-04, 2.86739639e-03,\n",
              "        3.24330018e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 8.05530159e-04, 5.27543527e-04,\n",
              "        5.11901469e-04, 3.29893970e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.93349496e-04,\n",
              "        2.25621025e-03, 1.39246406e-03, 1.60310358e-03, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        2.54861632e-03, 7.92015647e-05, 1.05338187e-03, 2.09660273e-04,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 2.59635713e-04, 5.40309465e-04, 2.24957431e-03,\n",
              "        3.36399473e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.05077850e-03, 1.60544183e-04,\n",
              "        1.22580326e-03, 2.09428335e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.45042672e-04,\n",
              "        8.10034471e-04, 1.08133185e-03, 7.31537706e-04, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.36726171e-03, 9.33767331e-04, 1.74053892e-03, 3.28344659e-03,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 1.50982562e-03, 1.68069847e-04, 2.07945030e-03,\n",
              "        7.29586071e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 6.11853003e-04, 1.15107246e-04,\n",
              "        1.04232906e-03, 1.41271535e-03, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.24642388e-03,\n",
              "        1.70660160e-04, 2.20705754e-03, 3.94026868e-03, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.44095919e-03, 2.28425525e-04, 1.63955321e-03, 1.55348619e-03,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 3.14647177e-04, 1.63277968e-03, 1.03803081e-03,\n",
              "        1.10690131e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 1.51020432e-03, 9.40671739e-04,\n",
              "        9.66891583e-04, 1.32190871e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.26831861e-04,\n",
              "        2.16980990e-03, 2.00071048e-03, 2.66035797e-03, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.00066293e-03, 4.14923987e-04, 1.19080241e-03, 3.07704146e-03,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 2.65011864e-04, 6.29044774e-05, 9.84684792e-04,\n",
              "        2.91915827e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.24301337e-03,\n",
              "        6.15950676e-03, 4.43332186e-02, 2.65781241e-03, 8.89289156e-03,\n",
              "        5.08165149e-02, 1.62666008e-04, 9.75197484e-03, 2.97276018e-02,\n",
              "        1.41108565e-03, 9.91772576e-03, 5.88138855e-02, 8.30732205e-05,\n",
              "        7.59748608e-03, 4.68420342e-02, 1.61541443e-03, 5.48183975e-03,\n",
              "        6.11969241e-02, 4.01287258e-03, 7.44744211e-03, 3.35757460e-02,\n",
              "        9.60678250e-05, 3.09990465e-03, 4.72231951e-02, 3.05422815e-03,\n",
              "        6.27734179e-03, 5.03387102e-02, 9.36228687e-05, 5.26227438e-04,\n",
              "        4.24101847e-02, 3.43754262e-03, 8.87189500e-03, 4.40234870e-02,\n",
              "        1.60585885e-04, 2.79237570e-04, 3.94649803e-02, 8.61743959e-05,\n",
              "        1.01873406e-02, 3.42848294e-02, 6.28821669e-05, 2.71513696e-04,\n",
              "        5.18933375e-02, 7.66659480e-04, 1.48540147e-03, 5.81485319e-02,\n",
              "        4.39962816e-03, 2.30739248e-03, 5.02250032e-02, 9.19351677e-04,\n",
              "        3.05031505e-04, 5.59049746e-02, 4.26418141e-03, 7.24288531e-03,\n",
              "        4.89917341e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.97594040e-04, 8.08968830e-03, 4.14293413e-02, 1.49338556e-04,\n",
              "        9.10989240e-04, 4.51579654e-02, 3.04839598e-04, 5.22648787e-03,\n",
              "        6.27307684e-02, 6.49165063e-05, 2.44013844e-04, 2.34291554e-02,\n",
              "        3.23601945e-03, 1.12545869e-02, 3.52804681e-02, 1.15985777e-04,\n",
              "        7.06791611e-04, 9.64531027e-03, 4.89855792e-04, 9.80092742e-03,\n",
              "        5.58977717e-02, 1.00945017e-03, 6.94268055e-03, 3.58605432e-02,\n",
              "        4.65955892e-04, 1.12164085e-03, 5.70915261e-02, 4.72943149e-03,\n",
              "        7.80318765e-03, 4.64975220e-02, 3.51064023e-03, 9.46025292e-03,\n",
              "        5.21409253e-02, 1.09453459e-04, 8.20804851e-03, 5.06463716e-02,\n",
              "        1.26040103e-04, 2.29318335e-03, 5.48280184e-03, 9.53027864e-05,\n",
              "        1.12996988e-03, 7.78560379e-02, 7.60570209e-04, 2.11555804e-03,\n",
              "        6.39069622e-02, 1.16965699e-03, 5.17428346e-04, 9.47791170e-03,\n",
              "        3.14016743e-04, 3.27745606e-03, 6.67759508e-02, 6.31224531e-03,\n",
              "        9.89429781e-03, 1.64269149e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 4.37809277e-03, 9.00812282e-03, 4.27393646e-02,\n",
              "        1.25114495e-04, 9.26240758e-03, 6.29012479e-02, 2.74531466e-03,\n",
              "        1.06534198e-02, 4.92653701e-02, 7.36795192e-05, 9.17284533e-03,\n",
              "        6.99045193e-02, 2.45147206e-04, 8.01348405e-04, 7.11292556e-02,\n",
              "        7.62997476e-04, 4.16121817e-04, 7.44882782e-02, 2.86141063e-03,\n",
              "        1.11175762e-03, 4.16465474e-02, 9.18510322e-05, 1.29195815e-03,\n",
              "        8.55799583e-02, 5.82358051e-03, 7.65857255e-03, 7.55128960e-02,\n",
              "        3.92031160e-03, 7.69542609e-03, 5.98744244e-02, 4.24060638e-03,\n",
              "        8.46619073e-03, 4.27027684e-02, 3.63286221e-03, 1.25060295e-02,\n",
              "        6.53466894e-03, 2.67157430e-03, 6.99958048e-03, 6.31319194e-02,\n",
              "        2.04358304e-04, 8.60364171e-03, 5.99393475e-02, 7.64589568e-04,\n",
              "        9.06710115e-03, 4.87594532e-02, 3.06857879e-04, 4.07571893e-03,\n",
              "        4.91435202e-02, 1.17770042e-04, 1.56608156e-03, 9.08567448e-03,\n",
              "        7.11182915e-04, 9.27069257e-04, 6.98177293e-02, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 8.19553106e-05, 6.17838625e-04,\n",
              "        4.12755778e-02, 2.45581425e-03, 6.92720283e-03, 3.92466649e-02,\n",
              "        1.41166006e-04, 1.89665834e-03, 4.79058593e-02, 3.86631087e-04,\n",
              "        9.51871813e-03, 5.61793856e-02, 1.56180766e-03, 4.87661424e-03,\n",
              "        3.05181803e-02, 1.34573983e-04, 5.03872365e-03, 5.43625108e-02,\n",
              "        3.71985081e-03, 4.54132712e-03, 4.77244375e-02, 9.02873645e-04,\n",
              "        2.53761591e-04, 5.08603926e-02, 4.76819388e-03, 6.60758125e-03,\n",
              "        5.15161009e-02, 3.92076171e-03, 5.07039231e-03, 5.11991279e-02,\n",
              "        3.16600915e-04, 8.86032389e-04, 3.98944958e-02, 7.02837575e-04,\n",
              "        1.46049471e-04, 4.05248981e-02, 9.61439671e-04, 3.32052883e-03,\n",
              "        4.69528840e-02, 7.42954162e-04, 5.99215247e-03, 5.04316625e-02,\n",
              "        3.99660280e-03, 7.70319856e-03, 5.01976068e-02, 1.21943509e-03,\n",
              "        1.23831201e-03, 5.26683189e-02, 1.73121744e-04, 4.99625040e-04,\n",
              "        5.19684631e-02, 1.00130807e-03, 2.56667992e-03, 4.94201448e-02,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.53536116e-04,\n",
              "        9.89967013e-03, 3.27236508e-02, 5.02590982e-04, 5.23216995e-03,\n",
              "        7.12204999e-02, 1.59398893e-03, 9.30038771e-03, 6.13474109e-02,\n",
              "        5.99760121e-05, 1.89789765e-03, 6.80232139e-02, 2.11964534e-04,\n",
              "        7.59129881e-03, 7.31700061e-02, 5.36035574e-03, 6.36755630e-03,\n",
              "        5.84908858e-02, 1.45887051e-04, 7.58486483e-03, 5.01495128e-02,\n",
              "        4.58180430e-03, 8.20016711e-03, 5.32180546e-02, 2.31538082e-04,\n",
              "        6.15009671e-04, 7.05886527e-02, 1.86477588e-04, 1.66557894e-03,\n",
              "        6.57299750e-02, 5.31137376e-03, 9.12540611e-03, 9.62500823e-03,\n",
              "        1.61965825e-04, 1.13230158e-02, 5.82037330e-02, 1.16686583e-04,\n",
              "        9.21671081e-04, 7.92264965e-02, 2.68597380e-03, 1.13851526e-03,\n",
              "        6.69916654e-02, 2.95998402e-03, 9.09292195e-03, 6.54999026e-02,\n",
              "        2.30798297e-04, 6.98214764e-03, 5.06641372e-02, 2.02058647e-04,\n",
              "        5.89261363e-03, 6.48564199e-02, 3.34073152e-04, 4.70590036e-04,\n",
              "        6.36208251e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        1.69692068e-03, 8.61427195e-03, 5.30212277e-02, 2.07680182e-03,\n",
              "        8.09852668e-03, 6.22767929e-02, 1.53066547e-04, 9.71018791e-03,\n",
              "        4.92326911e-02, 1.71555283e-04, 1.07706567e-02, 5.17953062e-02,\n",
              "        9.51232048e-05, 1.17119851e-03, 6.15788798e-02, 1.40671280e-03,\n",
              "        2.59247664e-03, 7.92784048e-02, 1.79578863e-04, 1.89072410e-03,\n",
              "        6.69904615e-02, 4.30701824e-03, 8.60220408e-03, 5.79168779e-02,\n",
              "        3.79899102e-03, 1.00247051e-02, 6.19120333e-02, 1.47616857e-04,\n",
              "        1.15505328e-02, 6.64985641e-02, 1.26480739e-04, 6.63162708e-04,\n",
              "        4.61363954e-02, 9.16491810e-05, 1.12431762e-03, 7.13431939e-02,\n",
              "        1.60449362e-04, 1.59423574e-03, 6.43114431e-02, 9.34205165e-04,\n",
              "        9.15197385e-04, 8.85609918e-02, 3.48359209e-03, 1.48609996e-03,\n",
              "        5.77447233e-02, 4.01629356e-03, 1.04147772e-02, 1.78900880e-02,\n",
              "        2.16829952e-03, 1.27249416e-02, 6.56966157e-02, 1.36432727e-03,\n",
              "        8.87127748e-03, 5.42987463e-02]),\n",
              " 'param_classifier': masked_array(data=[LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    LogisticRegression(), LogisticRegression(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier(),\n",
              "                    RandomForestClassifier(), RandomForestClassifier()],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_classifier__C': masked_array(data=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
              "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
              "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
              "                    1.0, 1.0, 1.0, 2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    2.7825594022071245, 2.7825594022071245,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    7.742636826811269, 7.742636826811269,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    21.544346900318832, 21.544346900318832,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    59.94842503189409, 59.94842503189409,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    166.81005372000593, 166.81005372000593,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    464.15888336127773, 464.15888336127773,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    1291.5496650148827, 1291.5496650148827,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626,\n",
              "                    3593.813663804626, 3593.813663804626, 10000.0, 10000.0,\n",
              "                    10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0,\n",
              "                    10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0,\n",
              "                    10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0,\n",
              "                    10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0,\n",
              "                    10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0,\n",
              "                    10000.0, 10000.0, 10000.0, 10000.0, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_classifier__max_iter': masked_array(data=[100, 100, 100, 100, 100, 100, 100, 100, 100, 150, 150,\n",
              "                    150, 150, 150, 150, 150, 150, 150, 200, 200, 200, 200,\n",
              "                    200, 200, 200, 200, 200, 300, 300, 300, 300, 300, 300,\n",
              "                    300, 300, 300, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 150, 150, 150, 150, 150, 150, 150, 150, 150, 200,\n",
              "                    200, 200, 200, 200, 200, 200, 200, 200, 300, 300, 300,\n",
              "                    300, 300, 300, 300, 300, 300, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 150, 150, 150, 150, 150, 150, 150,\n",
              "                    150, 150, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
              "                    300, 300, 300, 300, 300, 300, 300, 300, 300, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 150, 150, 150, 150,\n",
              "                    150, 150, 150, 150, 150, 200, 200, 200, 200, 200, 200,\n",
              "                    200, 200, 200, 300, 300, 300, 300, 300, 300, 300, 300,\n",
              "                    300, 100, 100, 100, 100, 100, 100, 100, 100, 100, 150,\n",
              "                    150, 150, 150, 150, 150, 150, 150, 150, 200, 200, 200,\n",
              "                    200, 200, 200, 200, 200, 200, 300, 300, 300, 300, 300,\n",
              "                    300, 300, 300, 300, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 150, 150, 150, 150, 150, 150, 150, 150, 150,\n",
              "                    200, 200, 200, 200, 200, 200, 200, 200, 200, 300, 300,\n",
              "                    300, 300, 300, 300, 300, 300, 300, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 150, 150, 150, 150, 150, 150,\n",
              "                    150, 150, 150, 200, 200, 200, 200, 200, 200, 200, 200,\n",
              "                    200, 300, 300, 300, 300, 300, 300, 300, 300, 300, 100,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 150, 150, 150,\n",
              "                    150, 150, 150, 150, 150, 150, 200, 200, 200, 200, 200,\n",
              "                    200, 200, 200, 200, 300, 300, 300, 300, 300, 300, 300,\n",
              "                    300, 300, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    150, 150, 150, 150, 150, 150, 150, 150, 150, 200, 200,\n",
              "                    200, 200, 200, 200, 200, 200, 200, 300, 300, 300, 300,\n",
              "                    300, 300, 300, 300, 300, 100, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 150, 150, 150, 150, 150, 150, 150, 150,\n",
              "                    150, 200, 200, 200, 200, 200, 200, 200, 200, 200, 300,\n",
              "                    300, 300, 300, 300, 300, 300, 300, 300, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_classifier__n_jobs': masked_array(data=[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "                    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_classifier__penalty': masked_array(data=['l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'elasticnet',\n",
              "                    'elasticnet', 'elasticnet', 'l1', 'l1', 'l1', 'l2',\n",
              "                    'l2', 'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_classifier__solver': masked_array(data=['newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear',\n",
              "                    'newton-cg', 'lbfgs', 'liblinear', 'newton-cg',\n",
              "                    'lbfgs', 'liblinear', 'newton-cg', 'lbfgs',\n",
              "                    'liblinear', 'newton-cg', 'lbfgs', 'liblinear', --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_classifier__verbose': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_classifier__bootstrap': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, True, True, True, True, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_classifier__max_depth': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_classifier__max_features': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
              "                    'auto', 'auto', 'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
              "                    'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
              "                    'log2'],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_classifier__min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
              "                    5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_classifier__min_samples_split': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, 2, 2, 2, 5, 5,\n",
              "                    5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2,\n",
              "                    5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2,\n",
              "                    2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10,\n",
              "                    10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10,\n",
              "                    10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5,\n",
              "                    10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5,\n",
              "                    5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2,\n",
              "                    2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10,\n",
              "                    2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10,\n",
              "                    10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10,\n",
              "                    10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5,\n",
              "                    10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5,\n",
              "                    5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2,\n",
              "                    2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10,\n",
              "                    2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10,\n",
              "                    10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10,\n",
              "                    10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5,\n",
              "                    10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5,\n",
              "                    5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2,\n",
              "                    2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10,\n",
              "                    2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10,\n",
              "                    10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10,\n",
              "                    10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5,\n",
              "                    10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5,\n",
              "                    5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2,\n",
              "                    2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10,\n",
              "                    2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10,\n",
              "                    10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10,\n",
              "                    10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5,\n",
              "                    10, 10, 10],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_classifier__n_estimators': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
              "                    --, --, --, --, --, --, --, --, --, --, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10,\n",
              "                    100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000,\n",
              "                    10, 100, 1000, 10, 100, 1000, 10, 100, 1000, 10, 100,\n",
              "                    1000, 10, 100, 1000, 10, 100, 1000, 10, 100, 1000],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                     True,  True,  True,  True,  True,  True,  True,  True,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 2.7825594022071245,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 7.742636826811269,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 21.544346900318832,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 59.94842503189409,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 166.81005372000593,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 464.15888336127773,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 1291.5496650148827,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 3593.813663804626,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 100,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 150,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 200,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l1',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'l2',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'newton-cg',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'lbfgs',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': LogisticRegression(),\n",
              "   'classifier__C': 10000.0,\n",
              "   'classifier__max_iter': 300,\n",
              "   'classifier__n_jobs': -1,\n",
              "   'classifier__penalty': 'elasticnet',\n",
              "   'classifier__solver': 'liblinear',\n",
              "   'classifier__verbose': 2},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': True,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 1,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 5,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'auto',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'sqrt',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 1,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 2,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 2,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 5,\n",
              "   'classifier__n_estimators': 1000},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 10},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 100},\n",
              "  {'classifier': RandomForestClassifier(),\n",
              "   'classifier__bootstrap': False,\n",
              "   'classifier__max_depth': 10,\n",
              "   'classifier__max_features': 'log2',\n",
              "   'classifier__min_samples_leaf': 5,\n",
              "   'classifier__min_samples_split': 10,\n",
              "   'classifier__n_estimators': 1000}],\n",
              " 'split0_test_score': array([       nan,        nan, 0.96      , 0.94461538, 0.94307692,\n",
              "        0.94461538,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96      , 0.94461538, 0.94461538, 0.94461538,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.95846154, 0.94461538, 0.94461538, 0.94461538,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96      ,\n",
              "        0.94461538, 0.94461538, 0.94461538,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96615385, 0.95230769,\n",
              "        0.95384615, 0.95230769,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96615385, 0.95230769, 0.95230769,\n",
              "        0.95230769,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96615385, 0.95230769, 0.95230769, 0.95230769,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96615385, 0.95230769, 0.95384615, 0.95230769,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97076923,\n",
              "        0.95846154, 0.95846154, 0.95846154,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97076923, 0.95846154,\n",
              "        0.95230769, 0.95846154,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97076923, 0.95846154, 0.95384615,\n",
              "        0.95846154,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97076923, 0.95846154, 0.96      , 0.95846154,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96769231, 0.96461538, 0.96461538, 0.96307692,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97230769,\n",
              "        0.96461538, 0.95076923, 0.96307692,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97230769, 0.96461538,\n",
              "        0.95384615, 0.96307692,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97230769, 0.96461538, 0.96307692,\n",
              "        0.96307692,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97384615, 0.97076923, 0.96461538, 0.96769231,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97384615, 0.97076923, 0.95846154, 0.96769231,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97384615,\n",
              "        0.97076923, 0.95692308, 0.96769231,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97384615, 0.97076923,\n",
              "        0.96615385, 0.96769231,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97384615, 0.97384615, 0.96615385,\n",
              "        0.97230769,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97384615, 0.97384615, 0.95692308, 0.97230769,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97384615, 0.97384615, 0.95384615, 0.97230769,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97384615,\n",
              "        0.97384615, 0.97076923, 0.97230769,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97384615, 0.97230769,\n",
              "        0.96      , 0.97384615,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97384615, 0.97230769, 0.96461538,\n",
              "        0.97384615,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97384615, 0.97230769, 0.95846154, 0.97384615,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97384615, 0.97230769, 0.97230769, 0.97384615,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97384615,\n",
              "        0.97230769, 0.96769231, 0.97230769,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97384615, 0.97230769,\n",
              "        0.95538462, 0.97230769,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97384615, 0.97230769, 0.96461538,\n",
              "        0.97230769,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97384615, 0.97230769, 0.96923077, 0.97230769,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97384615, 0.97230769, 0.96461538, 0.97230769,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97384615,\n",
              "        0.97230769, 0.95846154, 0.97230769,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97384615, 0.97230769,\n",
              "        0.96923077, 0.97230769,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97384615, 0.97230769, 0.97384615,\n",
              "        0.97230769,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97384615, 0.97384615, 0.96153846, 0.97230769,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97384615, 0.97384615, 0.94923077, 0.97230769,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97384615,\n",
              "        0.97384615, 0.95692308, 0.97230769,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97384615, 0.97384615,\n",
              "        0.97076923, 0.97230769,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.87076923, 0.87230769, 0.86923077,\n",
              "        0.86769231, 0.85846154, 0.86923077, 0.87384615, 0.88153846,\n",
              "        0.85384615, 0.79538462, 0.85692308, 0.87384615, 0.89538462,\n",
              "        0.88307692, 0.86615385, 0.85076923, 0.87692308, 0.86923077,\n",
              "        0.74923077, 0.88615385, 0.87384615, 0.80153846, 0.85384615,\n",
              "        0.86923077, 0.88461538, 0.83846154, 0.86615385, 0.81538462,\n",
              "        0.87692308, 0.86923077, 0.89538462, 0.88307692, 0.86615385,\n",
              "        0.88615385, 0.84461538, 0.86923077, 0.88307692, 0.88461538,\n",
              "        0.87384615, 0.88615385, 0.88      , 0.86615385, 0.77230769,\n",
              "        0.87846154, 0.86923077, 0.74923077, 0.84615385, 0.86923077,\n",
              "        0.89230769, 0.87230769, 0.86923077, 0.73692308, 0.87538462,\n",
              "        0.86615385,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.98923077, 0.98769231,\n",
              "        0.98923077, 0.99076923, 0.98769231, 0.98769231, 0.98923077,\n",
              "        0.98769231, 0.98923077, 0.98769231, 0.98923077, 0.98769231,\n",
              "        0.98769231, 0.98923077, 0.98769231, 0.98153846, 0.99076923,\n",
              "        0.98923077, 0.99538462, 0.98923077, 0.98923077, 0.98923077,\n",
              "        0.98923077, 0.98769231, 0.98769231, 0.98769231, 0.98923077,\n",
              "        0.98769231, 0.98769231, 0.98923077, 0.98769231, 0.98923077,\n",
              "        0.98923077, 0.98461538, 0.98923077, 0.98769231, 0.98769231,\n",
              "        0.98923077, 0.98923077, 0.98923077, 0.98769231, 0.98923077,\n",
              "        0.99230769, 0.98923077, 0.98769231, 0.98769231, 0.98923077,\n",
              "        0.98923077, 0.98769231, 0.98769231, 0.98769231, 0.99230769,\n",
              "        0.98923077, 0.98769231,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.99846154,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.86307692, 0.87230769, 0.86461538, 0.91230769, 0.85384615,\n",
              "        0.85692308, 0.81846154, 0.83384615, 0.86923077, 0.89692308,\n",
              "        0.86615385, 0.85692308, 0.77230769, 0.88307692, 0.86923077,\n",
              "        0.81846154, 0.86923077, 0.86615385, 0.85538462, 0.87076923,\n",
              "        0.87076923, 0.80923077, 0.87230769, 0.85692308, 0.85384615,\n",
              "        0.84153846, 0.86461538, 0.85076923, 0.86769231, 0.86923077,\n",
              "        0.87692308, 0.88      , 0.86615385, 0.84153846, 0.83384615,\n",
              "        0.85230769, 0.91384615, 0.85692308, 0.86615385, 0.78615385,\n",
              "        0.84615385, 0.86769231, 0.89692308, 0.84      , 0.85692308,\n",
              "        0.89692308, 0.84923077, 0.86923077, 0.84461538, 0.85076923,\n",
              "        0.86923077, 0.86923077, 0.90615385, 0.85384615,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.99384615, 0.98769231, 0.98769231, 0.99230769,\n",
              "        0.98769231, 0.98923077, 0.98769231, 0.98769231, 0.98923077,\n",
              "        0.98923077, 0.99230769, 0.98923077, 0.98769231, 0.98923077,\n",
              "        0.98923077, 0.98461538, 0.98769231, 0.98923077, 0.98923077,\n",
              "        0.98923077, 0.98923077, 0.98769231, 0.98923077, 0.98923077,\n",
              "        0.98923077, 0.98923077, 0.98769231, 0.98461538, 0.98923077,\n",
              "        0.98769231, 0.98923077, 0.98769231, 0.98923077, 0.98923077,\n",
              "        0.98923077, 0.98923077, 0.98923077, 0.98923077, 0.98923077,\n",
              "        0.99230769, 0.98923077, 0.98923077, 0.98923077, 0.98923077,\n",
              "        0.98923077, 0.99076923, 0.98769231, 0.98923077, 0.98769231,\n",
              "        0.98769231, 0.98923077, 0.98769231, 0.98769231, 0.98923077,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 0.99846154,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99846154, 0.99846154, 1.        ,\n",
              "        0.99846154, 0.99846154, 1.        , 1.        , 1.        ,\n",
              "        1.        ]),\n",
              " 'split1_test_score': array([       nan,        nan, 0.95692308, 0.95230769, 0.94923077,\n",
              "        0.95076923,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.95692308, 0.95230769, 0.95076923, 0.95076923,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.95692308, 0.95230769, 0.95076923, 0.95076923,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.95692308,\n",
              "        0.95230769, 0.95230769, 0.95076923,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96769231, 0.95230769,\n",
              "        0.95692308, 0.95384615,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96769231, 0.95230769, 0.94923077,\n",
              "        0.95384615,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96769231, 0.95230769, 0.95076923, 0.95384615,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96769231, 0.95230769, 0.95384615, 0.95384615,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96769231,\n",
              "        0.95538462, 0.95384615, 0.95692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96769231, 0.95538462,\n",
              "        0.95692308, 0.95692308,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96769231, 0.95538462, 0.95384615,\n",
              "        0.95692308,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96769231, 0.95538462, 0.95692308, 0.95692308,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96923077, 0.96615385, 0.96153846, 0.96307692,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96923077,\n",
              "        0.96615385, 0.95076923, 0.96307692,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96923077, 0.96615385,\n",
              "        0.95538462, 0.96307692,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96923077, 0.96615385, 0.96461538,\n",
              "        0.96307692,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96923077, 0.96769231, 0.96      , 0.96769231,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96923077, 0.96769231, 0.96      , 0.96769231,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96923077,\n",
              "        0.96769231, 0.94615385, 0.96769231,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96923077, 0.96769231,\n",
              "        0.96923077, 0.96769231,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96923077, 0.96923077, 0.96307692,\n",
              "        0.97076923,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96923077, 0.96923077, 0.95384615, 0.97076923,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96923077, 0.96923077, 0.94769231, 0.97076923,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96923077,\n",
              "        0.96923077, 0.97076923, 0.97076923,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96923077, 0.96769231,\n",
              "        0.96153846, 0.96923077,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96923077, 0.96769231, 0.95846154,\n",
              "        0.96923077,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96923077, 0.96769231, 0.94769231, 0.96923077,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96923077, 0.96769231, 0.96615385, 0.96923077,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96923077,\n",
              "        0.96769231, 0.96      , 0.96769231,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96923077, 0.96769231,\n",
              "        0.95846154, 0.96769231,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96923077, 0.96769231, 0.96307692,\n",
              "        0.96769231,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96923077, 0.96769231, 0.96615385, 0.96769231,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96923077, 0.96615385, 0.96307692, 0.96769231,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96923077,\n",
              "        0.96615385, 0.95384615, 0.96769231,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96923077, 0.96615385,\n",
              "        0.96153846, 0.96769231,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96923077, 0.96615385, 0.96615385,\n",
              "        0.96769231,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96923077, 0.96615385, 0.96307692, 0.96769231,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96923077, 0.96615385, 0.95846154, 0.96769231,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96923077,\n",
              "        0.96615385, 0.95230769, 0.96769231,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96923077, 0.96615385,\n",
              "        0.95846154, 0.96769231,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.79538462, 0.87076923, 0.88      ,\n",
              "        0.94923077, 0.87384615, 0.87230769, 0.83846154, 0.89692308,\n",
              "        0.87384615, 0.88615385, 0.87692308, 0.87846154, 0.83846154,\n",
              "        0.89692308, 0.88      , 0.92153846, 0.88461538, 0.87076923,\n",
              "        0.87538462, 0.88615385, 0.87230769, 0.82615385, 0.88615385,\n",
              "        0.87230769, 0.77384615, 0.89846154, 0.88      , 0.80923077,\n",
              "        0.88      , 0.87230769, 0.89538462, 0.88153846, 0.87384615,\n",
              "        0.84      , 0.89846154, 0.87384615, 0.76923077, 0.87230769,\n",
              "        0.88153846, 0.88615385, 0.86923077, 0.87384615, 0.78923077,\n",
              "        0.84923077, 0.88      , 0.86153846, 0.87230769, 0.87384615,\n",
              "        0.84769231, 0.91846154, 0.87384615, 0.86923077, 0.85692308,\n",
              "        0.87384615,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.99076923, 0.99076923,\n",
              "        0.98923077, 0.98923077, 0.98923077, 0.98923077, 0.98769231,\n",
              "        0.99076923, 0.98923077, 0.99076923, 0.98923077, 0.98923077,\n",
              "        0.98923077, 0.98923077, 0.98923077, 0.98769231, 0.98923077,\n",
              "        0.98923077, 0.98923077, 0.98923077, 0.98923077, 0.99076923,\n",
              "        0.98923077, 0.98923077, 0.98923077, 0.98923077, 0.98923077,\n",
              "        0.99076923, 0.98923077, 0.98923077, 0.98769231, 0.98923077,\n",
              "        0.98923077, 0.99076923, 0.99076923, 0.99076923, 0.99230769,\n",
              "        0.98923077, 0.98923077, 0.98923077, 0.98923077, 0.98923077,\n",
              "        0.98923077, 0.99076923, 0.98923077, 0.98923077, 0.98923077,\n",
              "        0.98923077, 0.98923077, 0.98923077, 0.98923077, 0.99076923,\n",
              "        0.98923077, 0.98923077,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99846154, 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.86615385, 0.85384615, 0.86923077, 0.84923077, 0.87076923,\n",
              "        0.87230769, 0.84307692, 0.90153846, 0.87076923, 0.79692308,\n",
              "        0.89230769, 0.87384615, 0.88769231, 0.87076923, 0.87230769,\n",
              "        0.88307692, 0.87538462, 0.87384615, 0.86615385, 0.87076923,\n",
              "        0.87384615, 0.85538462, 0.88153846, 0.86923077, 0.94461538,\n",
              "        0.87846154, 0.86923077, 0.85384615, 0.87846154, 0.87230769,\n",
              "        0.79384615, 0.85076923, 0.87230769, 0.85384615, 0.87384615,\n",
              "        0.88153846, 0.9       , 0.84769231, 0.87230769, 0.89846154,\n",
              "        0.9       , 0.87076923, 0.79384615, 0.88307692, 0.86923077,\n",
              "        0.88      , 0.87384615, 0.87230769, 0.91230769, 0.85384615,\n",
              "        0.87230769, 0.78461538, 0.88153846, 0.87076923,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.99076923, 0.98923077, 0.98923077, 0.98923077,\n",
              "        0.98923077, 0.98923077, 0.98923077, 0.98923077, 0.98923077,\n",
              "        0.98769231, 0.98923077, 0.98923077, 0.98769231, 0.98923077,\n",
              "        0.98923077, 0.98923077, 0.99076923, 0.98923077, 0.99076923,\n",
              "        0.98923077, 0.98923077, 0.98923077, 0.99076923, 0.98923077,\n",
              "        0.98923077, 0.98923077, 0.98923077, 0.99076923, 0.98923077,\n",
              "        0.98923077, 0.99076923, 0.98923077, 0.98923077, 0.99230769,\n",
              "        0.99076923, 0.98923077, 0.98923077, 0.98923077, 0.98923077,\n",
              "        0.98923077, 0.98923077, 0.98923077, 0.98923077, 0.99076923,\n",
              "        0.98923077, 0.99076923, 0.99076923, 0.98923077, 0.96307692,\n",
              "        0.98923077, 0.98923077, 0.99076923, 0.98923077, 0.98923077,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        ]),\n",
              " 'split2_test_score': array([       nan,        nan, 0.95538462, 0.93538462, 0.93538462,\n",
              "        0.93538462,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.95538462, 0.93538462, 0.93384615, 0.93538462,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.95538462, 0.93538462, 0.93538462, 0.93538462,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.95538462,\n",
              "        0.93538462, 0.93538462, 0.93538462,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96153846, 0.94153846,\n",
              "        0.94153846, 0.93846154,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96153846, 0.94153846, 0.94      ,\n",
              "        0.93846154,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96153846, 0.94153846, 0.93692308, 0.93846154,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96153846, 0.94153846, 0.94      , 0.93846154,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96769231,\n",
              "        0.95538462, 0.95230769, 0.95230769,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96769231, 0.95538462,\n",
              "        0.95230769, 0.95230769,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96769231, 0.95538462, 0.95384615,\n",
              "        0.95230769,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96769231, 0.95538462, 0.95230769, 0.95230769,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96769231, 0.96      , 0.95692308, 0.96      ,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96769231,\n",
              "        0.96      , 0.95230769, 0.96      ,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96769231, 0.96      ,\n",
              "        0.95384615, 0.96      ,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96769231, 0.96      , 0.96      ,\n",
              "        0.96      ,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96615385, 0.96615385, 0.95846154, 0.96307692,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96769231, 0.96615385, 0.95230769, 0.96307692,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96769231,\n",
              "        0.96615385, 0.95384615, 0.96307692,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96769231, 0.96615385,\n",
              "        0.96461538, 0.96307692,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96769231, 0.96769231, 0.96      ,\n",
              "        0.96769231,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96769231, 0.96769231, 0.95230769, 0.96769231,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96769231, 0.96769231, 0.95230769, 0.96769231,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96769231,\n",
              "        0.96769231, 0.96769231, 0.96769231,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96769231, 0.96769231,\n",
              "        0.95846154, 0.96769231,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96769231, 0.96769231, 0.95076923,\n",
              "        0.96769231,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96769231, 0.96769231, 0.95692308, 0.96769231,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96769231, 0.96769231, 0.96769231, 0.96769231,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96769231,\n",
              "        0.96615385, 0.95846154, 0.96615385,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96769231, 0.96615385,\n",
              "        0.94923077, 0.96615385,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96769231, 0.96615385, 0.96307692,\n",
              "        0.96615385,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96769231, 0.96615385, 0.96769231, 0.96615385,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96769231, 0.96769231, 0.96      , 0.96615385,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96769231,\n",
              "        0.96769231, 0.95384615, 0.96615385,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96769231, 0.96769231,\n",
              "        0.95692308, 0.96615385,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96769231, 0.96769231, 0.96923077,\n",
              "        0.96615385,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96615385, 0.96769231, 0.96      , 0.96615385,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96769231, 0.96769231, 0.95230769, 0.96615385,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96769231,\n",
              "        0.96769231, 0.96      , 0.96615385,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96769231, 0.96769231,\n",
              "        0.96615385, 0.96615385,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.89384615, 0.87384615, 0.89846154,\n",
              "        0.87538462, 0.88615385, 0.88769231, 0.87384615, 0.88769231,\n",
              "        0.88615385, 0.87538462, 0.88153846, 0.90153846, 0.88153846,\n",
              "        0.89846154, 0.89230769, 0.81692308, 0.88923077, 0.88769231,\n",
              "        0.88769231, 0.92      , 0.89076923, 0.87692308, 0.87538462,\n",
              "        0.88461538, 0.83230769, 0.91230769, 0.88769231, 0.91846154,\n",
              "        0.88      , 0.91384615, 0.92615385, 0.89076923, 0.88615385,\n",
              "        0.90461538, 0.90769231, 0.88      , 0.90923077, 0.90923077,\n",
              "        0.88461538, 0.86307692, 0.89846154, 0.90923077, 0.86307692,\n",
              "        0.89692308, 0.88769231, 0.79692308, 0.90461538, 0.89076923,\n",
              "        0.90153846, 0.88307692, 0.89692308, 0.9       , 0.88461538,\n",
              "        0.88615385,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.98461538, 0.98769231,\n",
              "        0.98461538, 0.98923077, 0.98461538, 0.98461538, 0.98461538,\n",
              "        0.98615385, 0.98461538, 0.98461538, 0.98461538, 0.98461538,\n",
              "        0.98153846, 0.98461538, 0.98461538, 0.98461538, 0.98461538,\n",
              "        0.98615385, 0.97384615, 0.98153846, 0.98153846, 0.98769231,\n",
              "        0.98153846, 0.98153846, 0.98      , 0.98461538, 0.98153846,\n",
              "        0.99076923, 0.98461538, 0.98461538, 0.98461538, 0.98461538,\n",
              "        0.98461538, 0.98307692, 0.98769231, 0.98461538, 0.98      ,\n",
              "        0.98615385, 0.98461538, 0.98769231, 0.98461538, 0.98615385,\n",
              "        0.99076923, 0.98461538, 0.98461538, 0.98461538, 0.98307692,\n",
              "        0.98153846, 0.98153846, 0.98307692, 0.98153846, 0.98615385,\n",
              "        0.98307692, 0.98153846,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99692308, 1.        , 1.        ,\n",
              "        0.99692308, 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.91538462, 0.91538462, 0.89846154, 0.82769231, 0.88769231,\n",
              "        0.90153846, 0.84153846, 0.88153846, 0.89230769, 0.91384615,\n",
              "        0.88461538, 0.90769231, 0.84923077, 0.91230769, 0.89230769,\n",
              "        0.88      , 0.89692308, 0.90615385, 0.88      , 0.91076923,\n",
              "        0.90769231, 0.86615385, 0.89076923, 0.90769231, 0.84923077,\n",
              "        0.87846154, 0.88615385, 0.89538462, 0.87846154, 0.90461538,\n",
              "        0.89384615, 0.90923077, 0.89076923, 0.85692308, 0.91230769,\n",
              "        0.90615385, 0.90153846, 0.87846154, 0.90923077, 0.86307692,\n",
              "        0.88153846, 0.9       , 0.88307692, 0.89846154, 0.89076923,\n",
              "        0.90769231, 0.90923077, 0.89538462, 0.86      , 0.87230769,\n",
              "        0.90769231, 0.84769231, 0.90769231, 0.9       ,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.98153846, 0.98461538, 0.98461538, 0.98461538,\n",
              "        0.98615385, 0.98461538, 0.98461538, 0.98615385, 0.98461538,\n",
              "        0.98461538, 0.98769231, 0.98461538, 0.99076923, 0.98461538,\n",
              "        0.98615385, 0.97692308, 0.98461538, 0.98461538, 0.98615385,\n",
              "        0.98461538, 0.98153846, 0.98769231, 0.98461538, 0.98307692,\n",
              "        0.98461538, 0.98307692, 0.98153846, 0.98615385, 0.98769231,\n",
              "        0.98461538, 0.98461538, 0.98461538, 0.98461538, 0.99076923,\n",
              "        0.98461538, 0.98615385, 0.97692308, 0.98461538, 0.98461538,\n",
              "        0.98461538, 0.98461538, 0.98461538, 0.97384615, 0.98769231,\n",
              "        0.98461538, 0.98461538, 0.98153846, 0.98153846, 0.98461538,\n",
              "        0.98307692, 0.98153846, 0.98769231, 0.98615385, 0.98153846,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.99692308, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        ]),\n",
              " 'split3_test_score': array([       nan,        nan, 0.98      , 0.96769231, 0.96923077,\n",
              "        0.96769231,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.98      , 0.96769231, 0.96769231, 0.96769231,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.98      , 0.96769231, 0.96769231, 0.96769231,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.98      ,\n",
              "        0.96769231, 0.96769231, 0.96769231,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.98461538, 0.97384615,\n",
              "        0.97230769, 0.97384615,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.98769231, 0.97384615, 0.97538462,\n",
              "        0.97384615,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.98461538, 0.97384615, 0.97538462, 0.97384615,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.98461538, 0.97384615, 0.97384615, 0.97384615,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.98769231,\n",
              "        0.98      , 0.98307692, 0.98      ,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.98769231, 0.98      ,\n",
              "        0.97846154, 0.98      ,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.98769231, 0.98      , 0.98461538,\n",
              "        0.98      ,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.98769231, 0.98      , 0.98      , 0.98      ,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.98769231, 0.98153846, 0.98307692, 0.98      ,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.98769231,\n",
              "        0.98153846, 0.97692308, 0.98      ,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.98769231, 0.98153846,\n",
              "        0.97846154, 0.98      ,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.98769231, 0.98153846, 0.98461538,\n",
              "        0.98      ,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.98769231, 0.98769231, 0.98461538, 0.98615385,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.98769231, 0.98769231, 0.98      , 0.98615385,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.98769231,\n",
              "        0.98769231, 0.97846154, 0.98615385,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.98769231, 0.98769231,\n",
              "        0.99076923, 0.98615385,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.98769231, 0.98769231, 0.98307692,\n",
              "        0.98769231,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.98769231, 0.98769231, 0.98153846, 0.98769231,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.98769231, 0.98769231, 0.98769231, 0.98769231,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.98769231,\n",
              "        0.98769231, 0.98615385, 0.98769231,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.98769231, 0.98615385,\n",
              "        0.98615385, 0.98615385,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.98769231, 0.98615385, 0.98153846,\n",
              "        0.98615385,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.98769231, 0.98615385, 0.97692308, 0.98615385,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.98769231, 0.98615385, 0.99076923, 0.98615385,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.98769231,\n",
              "        0.98615385, 0.98461538, 0.98615385,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.98769231, 0.98615385,\n",
              "        0.98      , 0.98615385,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.98769231, 0.98615385, 0.97846154,\n",
              "        0.98615385,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.98769231, 0.98615385, 0.98769231, 0.98615385,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.98769231, 0.98615385, 0.98307692, 0.98615385,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.98769231,\n",
              "        0.98615385, 0.97846154, 0.98615385,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.98769231, 0.98615385,\n",
              "        0.97692308, 0.98615385,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.98769231, 0.98615385, 0.98615385,\n",
              "        0.98615385,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.98615385, 0.98615385, 0.98153846, 0.98615385,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.98769231, 0.98615385, 0.98      , 0.98615385,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.98769231,\n",
              "        0.98615385, 0.97846154, 0.98615385,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.98615385, 0.98615385,\n",
              "        0.98615385, 0.98615385,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.85538462, 0.88307692, 0.89538462,\n",
              "        0.77692308, 0.88153846, 0.88923077, 0.86769231, 0.88923077,\n",
              "        0.89076923, 0.85846154, 0.89538462, 0.88769231, 0.76923077,\n",
              "        0.91076923, 0.89692308, 0.9       , 0.9       , 0.89538462,\n",
              "        0.81846154, 0.92615385, 0.89538462, 0.80615385, 0.88      ,\n",
              "        0.89692308, 0.79384615, 0.89230769, 0.89076923, 0.80461538,\n",
              "        0.87538462, 0.89538462, 0.89538462, 0.86153846, 0.89538462,\n",
              "        0.84      , 0.86307692, 0.88615385, 0.88307692, 0.88307692,\n",
              "        0.89076923, 0.83384615, 0.91384615, 0.89076923, 0.83384615,\n",
              "        0.89692308, 0.89076923, 0.76769231, 0.91538462, 0.89538462,\n",
              "        0.82307692, 0.88307692, 0.88769231, 0.78923077, 0.86      ,\n",
              "        0.89846154,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99538462, 0.99384615,\n",
              "        0.99384615, 0.99538462, 0.99692308, 0.99538462, 0.99384615,\n",
              "        0.98923077, 0.99384615, 0.99384615, 0.99384615, 0.99538462,\n",
              "        0.99384615, 0.99076923, 0.99076923, 0.99076923, 0.98923077,\n",
              "        0.99076923, 0.99230769, 0.99692308, 0.99230769, 0.99076923,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99538462,\n",
              "        0.99538462, 0.99076923, 0.99384615, 0.99538462, 0.99538462,\n",
              "        0.99538462, 0.99538462, 1.        , 0.99538462, 0.99384615,\n",
              "        0.99538462, 0.99384615, 0.99384615, 0.99384615, 0.99076923,\n",
              "        0.99076923, 0.98923077, 0.99230769, 0.99230769, 0.99230769,\n",
              "        0.99384615, 0.99076923,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.83384615, 0.89538462, 0.88923077, 0.86      , 0.87384615,\n",
              "        0.88923077, 0.82923077, 0.91076923, 0.89538462, 0.84153846,\n",
              "        0.9       , 0.87846154, 0.93384615, 0.88769231, 0.89538462,\n",
              "        0.89692308, 0.86461538, 0.89384615, 0.75384615, 0.88769231,\n",
              "        0.89538462, 0.85846154, 0.89076923, 0.88923077, 0.90769231,\n",
              "        0.89846154, 0.9       , 0.90769231, 0.89076923, 0.89538462,\n",
              "        0.84923077, 0.86307692, 0.90461538, 0.92769231, 0.87538462,\n",
              "        0.90307692, 0.88923077, 0.88307692, 0.88923077, 0.86461538,\n",
              "        0.89846154, 0.89384615, 0.83538462, 0.87384615, 0.89538462,\n",
              "        0.86153846, 0.89846154, 0.88923077, 0.88769231, 0.86      ,\n",
              "        0.89846154, 0.87692308, 0.89076923, 0.89076923,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.99538462, 0.99384615, 0.99384615, 0.98769231,\n",
              "        0.99538462, 0.99538462, 0.99384615, 0.99538462, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99538462,\n",
              "        0.99384615, 0.99076923, 0.99538462, 0.99538462, 0.99384615,\n",
              "        0.99384615, 0.99076923, 0.99076923, 0.99538462, 0.99230769,\n",
              "        0.99384615, 0.99076923, 0.99230769, 0.99538462, 0.99538462,\n",
              "        0.99384615, 0.98769231, 0.99538462, 0.99538462, 0.99384615,\n",
              "        0.99384615, 0.99538462, 0.99384615, 0.99384615, 0.99538462,\n",
              "        0.98923077, 0.99538462, 0.99538462, 0.99692308, 0.99538462,\n",
              "        0.99384615, 0.99230769, 0.99076923, 0.99230769, 0.99846154,\n",
              "        0.99076923, 0.99076923, 0.99384615, 0.99230769, 0.99076923,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        0.99692308, 0.99846154, 1.        , 1.        , 1.        ,\n",
              "        1.        ]),\n",
              " 'split4_test_score': array([       nan,        nan, 0.96923077, 0.95846154, 0.95846154,\n",
              "        0.95846154,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96923077, 0.95846154, 0.95846154, 0.95846154,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96923077, 0.95846154, 0.95846154, 0.95846154,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96923077,\n",
              "        0.95846154, 0.95846154, 0.95846154,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.96153846,\n",
              "        0.96      , 0.96      ,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.96153846, 0.96      ,\n",
              "        0.96      ,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97692308, 0.96153846, 0.96      , 0.96      ,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.96153846, 0.96153846, 0.96      ,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97846154,\n",
              "        0.96923077, 0.96923077, 0.96769231,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97846154, 0.96923077,\n",
              "        0.96615385, 0.96769231,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97846154, 0.96923077, 0.96      ,\n",
              "        0.96769231,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97846154, 0.96923077, 0.96923077, 0.96769231,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.97538462, 0.96923077, 0.97230769,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.97538462, 0.96      , 0.97230769,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97538462,\n",
              "        0.97384615, 0.97230769,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.97538462, 0.97384615,\n",
              "        0.97230769,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97692308, 0.97846154, 0.97076923, 0.97692308,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.97846154, 0.95846154, 0.97692308,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.97846154, 0.96307692, 0.97692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97846154,\n",
              "        0.97846154, 0.97692308,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.97692308, 0.97076923,\n",
              "        0.97846154,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97692308, 0.97692308, 0.97076923, 0.97846154,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.97692308, 0.96461538, 0.97846154,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.97692308, 0.97538462, 0.97846154,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97692308,\n",
              "        0.97076923, 0.97692308,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.97692308, 0.96153846,\n",
              "        0.97692308,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97692308, 0.97692308, 0.97076923, 0.97692308,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.97692308, 0.97538462, 0.97692308,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.97692308, 0.97076923, 0.97692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97692308,\n",
              "        0.96923077, 0.97692308,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.97692308, 0.96307692,\n",
              "        0.97692308,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97692308, 0.97692308, 0.97538462, 0.97692308,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.97692308, 0.97076923, 0.97692308,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.97692308, 0.96769231, 0.97692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97692308,\n",
              "        0.96307692, 0.97692308,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.97692308, 0.97692308,\n",
              "        0.97692308,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97846154, 0.97692308, 0.97076923, 0.97692308,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.97692308, 0.95692308, 0.97692308,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.97692308, 0.96615385, 0.97692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97692308,\n",
              "        0.97538462, 0.97692308,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.81538462, 0.88461538, 0.88461538,\n",
              "        0.91692308, 0.88153846, 0.88769231, 0.80615385, 0.87384615,\n",
              "        0.87846154, 0.85846154, 0.89538462, 0.88615385, 0.88615385,\n",
              "        0.88307692, 0.88615385, 0.9       , 0.87846154, 0.88461538,\n",
              "        0.92153846, 0.91538462, 0.88615385, 0.90153846, 0.88615385,\n",
              "        0.88153846, 0.87230769, 0.88923077, 0.88769231, 0.85846154,\n",
              "        0.88      , 0.88461538, 0.92      , 0.89384615, 0.88615385,\n",
              "        0.84307692, 0.88461538, 0.87846154, 0.89230769, 0.88      ,\n",
              "        0.88615385, 0.87384615, 0.87384615, 0.88615385, 0.89846154,\n",
              "        0.88307692, 0.88615385, 0.88615385, 0.88153846, 0.88615385,\n",
              "        0.87384615, 0.87846154, 0.88461538, 0.89538462, 0.90153846,\n",
              "        0.88615385,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.99230769, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99230769, 0.99076923, 0.99230769,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99230769,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99230769, 0.99076923, 0.99076923,\n",
              "        0.98923077, 0.99076923, 0.99076923, 0.99230769, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99230769, 0.99076923, 0.98769231, 0.99076923, 0.99076923,\n",
              "        0.99230769, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99230769, 0.99076923, 0.99076923, 0.98307692,\n",
              "        0.99076923, 0.99076923,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99846154, 1.        , 1.        ,\n",
              "        0.99846154, 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.86769231, 0.88307692, 0.88461538, 0.91846154, 0.93384615,\n",
              "        0.88923077, 0.89692308, 0.88461538, 0.88461538, 0.88461538,\n",
              "        0.88461538, 0.88      , 0.82307692, 0.90307692, 0.88      ,\n",
              "        0.87230769, 0.87846154, 0.88153846, 0.91230769, 0.90307692,\n",
              "        0.88153846, 0.83692308, 0.88615385, 0.88153846, 0.9       ,\n",
              "        0.88769231, 0.88      , 0.80307692, 0.88      , 0.87846154,\n",
              "        0.82307692, 0.89076923, 0.87846154, 0.88      , 0.87538462,\n",
              "        0.88307692, 0.82461538, 0.88      , 0.87846154, 0.86153846,\n",
              "        0.88      , 0.88      , 0.86      , 0.88923077, 0.88307692,\n",
              "        0.84769231, 0.89230769, 0.88153846, 0.90153846, 0.86615385,\n",
              "        0.88      , 0.90769231, 0.88      , 0.88      ,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.99076923, 0.99230769, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.98923077,\n",
              "        0.99076923, 0.99076923, 0.99230769, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99230769, 0.99076923,\n",
              "        0.99230769, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99230769, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.98923077, 0.99076923, 0.99076923, 0.99230769,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        ]),\n",
              " 'split5_test_score': array([       nan,        nan, 0.96769231, 0.96      , 0.95846154,\n",
              "        0.95846154,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96769231, 0.96      , 0.95692308, 0.95846154,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96615385, 0.96      , 0.95692308, 0.95846154,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96769231,\n",
              "        0.96      , 0.96      , 0.95846154,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96923077, 0.95846154,\n",
              "        0.96307692, 0.95846154,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96923077, 0.95846154, 0.95846154,\n",
              "        0.95846154,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96923077, 0.95846154, 0.95692308, 0.95846154,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96923077, 0.95846154, 0.95846154, 0.95846154,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96769231,\n",
              "        0.96461538, 0.96769231, 0.96307692,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96769231, 0.96461538,\n",
              "        0.95846154, 0.96307692,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96769231, 0.96461538, 0.95538462,\n",
              "        0.96307692,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96769231, 0.96461538, 0.96615385, 0.96307692,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96769231, 0.96923077, 0.96923077, 0.96769231,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96769231,\n",
              "        0.96923077, 0.96153846, 0.96769231,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96769231, 0.96923077,\n",
              "        0.96461538, 0.96769231,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96769231, 0.96923077, 0.96923077,\n",
              "        0.96769231,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96769231, 0.96923077, 0.96769231, 0.96923077,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96769231, 0.96923077, 0.94769231, 0.96923077,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96923077,\n",
              "        0.96923077, 0.96307692, 0.96923077,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96769231, 0.96923077,\n",
              "        0.96769231, 0.96923077,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96923077, 0.96769231, 0.96923077,\n",
              "        0.96769231,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96769231, 0.96769231, 0.95230769, 0.96769231,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96923077, 0.96769231, 0.95692308, 0.96769231,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96923077,\n",
              "        0.96769231, 0.96615385, 0.96769231,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96923077, 0.97076923,\n",
              "        0.96923077, 0.96923077,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96923077, 0.97076923, 0.94      ,\n",
              "        0.96923077,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96923077, 0.97076923, 0.96461538, 0.96923077,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96923077, 0.97076923, 0.97076923, 0.96923077,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96923077,\n",
              "        0.97076923, 0.96615385, 0.97076923,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96923077, 0.97076923,\n",
              "        0.95846154, 0.97076923,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96923077, 0.97076923, 0.95846154,\n",
              "        0.97076923,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96923077, 0.97076923, 0.97076923, 0.97076923,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96923077, 0.97076923, 0.96769231, 0.97076923,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96769231,\n",
              "        0.97076923, 0.94769231, 0.97076923,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96923077, 0.97076923,\n",
              "        0.96615385, 0.97076923,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96923077, 0.97076923, 0.97076923,\n",
              "        0.97076923,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96923077, 0.97076923, 0.96769231, 0.97076923,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96923077, 0.97076923, 0.95076923, 0.97076923,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96923077,\n",
              "        0.97076923, 0.97076923, 0.97076923,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96923077, 0.97076923,\n",
              "        0.97076923, 0.97076923,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.86461538, 0.92615385, 0.89538462,\n",
              "        0.82153846, 0.89846154, 0.89538462, 0.77230769, 0.93076923,\n",
              "        0.89538462, 0.85692308, 0.91692308, 0.91384615, 0.86461538,\n",
              "        0.89384615, 0.89230769, 0.86769231, 0.89538462, 0.9       ,\n",
              "        0.82153846, 0.89230769, 0.90461538, 0.89230769, 0.90153846,\n",
              "        0.90307692, 0.91230769, 0.90615385, 0.89538462, 0.86153846,\n",
              "        0.91692308, 0.90153846, 0.81384615, 0.90307692, 0.89076923,\n",
              "        0.88153846, 0.88615385, 0.87692308, 0.88461538, 0.89538462,\n",
              "        0.90923077, 0.90923077, 0.89230769, 0.89076923, 0.89692308,\n",
              "        0.88923077, 0.89076923, 0.88      , 0.92      , 0.89076923,\n",
              "        0.83692308, 0.89230769, 0.89538462, 0.95076923, 0.89384615,\n",
              "        0.89076923,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.99384615, 0.99230769,\n",
              "        0.99230769, 0.99230769, 0.99230769, 0.99230769, 0.99384615,\n",
              "        0.99230769, 0.99230769, 0.99230769, 0.99230769, 0.99230769,\n",
              "        0.99230769, 0.99230769, 0.99230769, 0.99538462, 0.99230769,\n",
              "        0.99230769, 0.99230769, 0.99230769, 0.99230769, 0.99538462,\n",
              "        0.99230769, 0.99230769, 0.98615385, 0.99230769, 0.99230769,\n",
              "        0.99384615, 0.99230769, 0.99230769, 0.99230769, 0.99230769,\n",
              "        0.99230769, 0.97384615, 0.99230769, 0.99230769, 0.99384615,\n",
              "        0.99230769, 0.99230769, 0.99384615, 0.99230769, 0.99230769,\n",
              "        0.99230769, 0.99384615, 0.99230769, 0.99076923, 0.99384615,\n",
              "        0.99230769, 0.99384615, 0.99230769, 0.99230769, 0.99230769,\n",
              "        0.99230769, 0.99230769,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99846154, 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99846154, 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.89230769, 0.91076923, 0.89076923, 0.82153846, 0.90153846,\n",
              "        0.89076923, 0.89384615, 0.87692308, 0.89076923, 0.93076923,\n",
              "        0.90615385, 0.89538462, 0.91076923, 0.89384615, 0.89076923,\n",
              "        0.79692308, 0.91692308, 0.89538462, 0.88923077, 0.90153846,\n",
              "        0.89538462, 0.86615385, 0.90923077, 0.89538462, 0.82461538,\n",
              "        0.89230769, 0.91076923, 0.90307692, 0.87692308, 0.89538462,\n",
              "        0.85076923, 0.86307692, 0.87692308, 0.85692308, 0.86153846,\n",
              "        0.89230769, 0.89846154, 0.87692308, 0.89538462, 0.86615385,\n",
              "        0.91076923, 0.89538462, 0.92307692, 0.88615385, 0.91384615,\n",
              "        0.83538462, 0.89538462, 0.89076923, 0.85538462, 0.89692308,\n",
              "        0.88153846, 0.90307692, 0.92769231, 0.89076923,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.99384615, 0.99230769, 0.99230769, 0.99384615,\n",
              "        0.99230769, 0.99230769, 0.99384615, 0.99384615, 0.99230769,\n",
              "        0.99230769, 0.99230769, 0.99230769, 0.99384615, 0.99230769,\n",
              "        0.99230769, 0.99230769, 0.99230769, 0.99230769, 0.99230769,\n",
              "        0.99230769, 0.99230769, 0.99230769, 0.99230769, 0.99230769,\n",
              "        0.99230769, 0.99230769, 0.99230769, 0.99384615, 0.99230769,\n",
              "        0.99230769, 0.98923077, 0.99384615, 0.99230769, 0.99384615,\n",
              "        0.99384615, 0.99230769, 0.98769231, 0.99230769, 0.99230769,\n",
              "        0.99230769, 0.99230769, 0.99230769, 0.99230769, 0.99230769,\n",
              "        0.99230769, 0.99384615, 0.99230769, 0.99230769, 0.98769231,\n",
              "        0.99230769, 0.99230769, 0.99384615, 0.99384615, 0.99230769,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        ]),\n",
              " 'split6_test_score': array([       nan,        nan, 0.95230769, 0.94153846, 0.94307692,\n",
              "        0.94153846,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.95230769, 0.94153846, 0.94153846, 0.94153846,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.95384615, 0.94153846, 0.94153846, 0.94153846,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.95384615,\n",
              "        0.94153846, 0.94153846, 0.94153846,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96153846, 0.94461538,\n",
              "        0.94615385, 0.94461538,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96307692, 0.94461538, 0.94153846,\n",
              "        0.94461538,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96307692, 0.94461538, 0.94307692, 0.94461538,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96153846, 0.94461538, 0.94461538, 0.94461538,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96461538,\n",
              "        0.94923077, 0.95230769, 0.94769231,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96461538, 0.94923077,\n",
              "        0.94769231, 0.94769231,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96461538, 0.94923077, 0.94461538,\n",
              "        0.94769231,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96461538, 0.94923077, 0.94923077, 0.94769231,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96615385, 0.96153846, 0.95230769, 0.95692308,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96615385,\n",
              "        0.96153846, 0.95384615, 0.95692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96615385, 0.96153846,\n",
              "        0.94769231, 0.95692308,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96615385, 0.96153846, 0.95692308,\n",
              "        0.95692308,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96615385, 0.96461538, 0.95384615, 0.96307692,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96615385, 0.96461538, 0.96      , 0.96307692,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96615385,\n",
              "        0.96461538, 0.95384615, 0.96307692,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96615385, 0.96461538,\n",
              "        0.96461538, 0.96307692,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96615385, 0.96615385, 0.95076923,\n",
              "        0.96461538,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96615385, 0.96615385, 0.95230769, 0.96461538,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96615385, 0.96615385, 0.94615385, 0.96461538,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96615385,\n",
              "        0.96615385, 0.96461538, 0.96461538,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96615385, 0.96307692,\n",
              "        0.95384615, 0.96461538,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96615385, 0.96307692, 0.96      ,\n",
              "        0.96461538,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96615385, 0.96307692, 0.95692308, 0.96461538,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96615385, 0.96307692, 0.96153846, 0.96461538,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96615385,\n",
              "        0.96153846, 0.95384615, 0.96307692,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96615385, 0.96153846,\n",
              "        0.94461538, 0.96307692,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96615385, 0.96153846, 0.95846154,\n",
              "        0.96307692,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96615385, 0.96153846, 0.95846154, 0.96307692,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96615385, 0.96153846, 0.95230769, 0.96307692,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96615385,\n",
              "        0.96153846, 0.96307692, 0.96307692,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96615385, 0.96153846,\n",
              "        0.95076923, 0.96307692,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96615385, 0.96153846, 0.95692308,\n",
              "        0.96307692,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96615385, 0.96153846, 0.95230769, 0.96153846,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96615385, 0.96153846, 0.95692308, 0.96153846,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96615385,\n",
              "        0.96153846, 0.94307692, 0.96153846,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96615385, 0.96153846,\n",
              "        0.96153846, 0.96153846,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.86      , 0.87384615, 0.89076923,\n",
              "        0.92615385, 0.91538462, 0.88769231, 0.89230769, 0.88153846,\n",
              "        0.89076923, 0.84461538, 0.91076923, 0.89076923, 0.9       ,\n",
              "        0.88153846, 0.88307692, 0.81384615, 0.88307692, 0.88615385,\n",
              "        0.90769231, 0.89538462, 0.88615385, 0.87692308, 0.88769231,\n",
              "        0.88307692, 0.84615385, 0.87076923, 0.88615385, 0.88307692,\n",
              "        0.89384615, 0.88461538, 0.82923077, 0.87692308, 0.89538462,\n",
              "        0.88615385, 0.88307692, 0.9       , 0.84615385, 0.88615385,\n",
              "        0.88769231, 0.81230769, 0.90615385, 0.88769231, 0.79538462,\n",
              "        0.87384615, 0.88769231, 0.84461538, 0.89846154, 0.88      ,\n",
              "        0.87384615, 0.88      , 0.88615385, 0.92      , 0.86615385,\n",
              "        0.89692308,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.98153846, 0.99230769,\n",
              "        0.99076923, 0.99230769, 0.99230769, 0.99076923, 0.99076923,\n",
              "        0.99230769, 0.99076923, 0.98923077, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99230769,\n",
              "        0.99076923, 0.99538462, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99384615, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99230769, 0.99076923, 0.99076923,\n",
              "        0.98615385, 0.99076923, 0.99076923, 0.98923077, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99230769,\n",
              "        0.99076923, 0.99076923,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.87384615, 0.88923077, 0.88615385, 0.88153846, 0.86615385,\n",
              "        0.88615385, 0.88615385, 0.89846154, 0.88307692, 0.78307692,\n",
              "        0.87076923, 0.88      , 0.90153846, 0.9       , 0.88615385,\n",
              "        0.86307692, 0.87692308, 0.88153846, 0.80461538, 0.88307692,\n",
              "        0.88769231, 0.91538462, 0.89076923, 0.88615385, 0.90461538,\n",
              "        0.87076923, 0.89076923, 0.89076923, 0.89846154, 0.89538462,\n",
              "        0.87538462, 0.89538462, 0.89230769, 0.79230769, 0.89846154,\n",
              "        0.88153846, 0.81538462, 0.88923077, 0.88153846, 0.90153846,\n",
              "        0.89538462, 0.88615385, 0.86461538, 0.90153846, 0.88461538,\n",
              "        0.88307692, 0.89230769, 0.87846154, 0.81538462, 0.88      ,\n",
              "        0.89384615, 0.83692308, 0.88307692, 0.88615385,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.99230769, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99230769, 0.99230769, 0.99076923, 0.99230769, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99076923, 0.99230769, 0.99076923, 0.99076923,\n",
              "        0.99076923, 0.99230769, 0.99076923, 0.99846154, 0.99076923,\n",
              "        0.99076923, 0.99230769, 0.99230769, 0.99076923, 0.99230769,\n",
              "        0.99230769, 0.99076923, 0.99076923, 0.99230769, 0.99076923,\n",
              "        0.99384615, 0.99076923, 0.99076923, 0.99538462, 0.99076923,\n",
              "        0.99230769, 0.98615385, 0.99076923, 0.99076923, 0.99384615,\n",
              "        0.99076923, 0.99076923, 0.99076923, 0.99076923, 0.99076923,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        ]),\n",
              " 'split7_test_score': array([       nan,        nan, 0.97538462, 0.96461538, 0.96461538,\n",
              "        0.96461538,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97538462, 0.96461538, 0.96461538, 0.96461538,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97538462, 0.96461538, 0.96307692, 0.96461538,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97538462,\n",
              "        0.96461538, 0.96461538, 0.96461538,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97076923,\n",
              "        0.96769231, 0.97076923,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.97076923, 0.97076923,\n",
              "        0.97076923,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97692308, 0.97076923, 0.97076923, 0.97076923,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.97076923, 0.97230769, 0.97076923,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.97538462, 0.97538462, 0.97538462,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97538462,\n",
              "        0.97384615, 0.97538462,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.97538462, 0.97384615,\n",
              "        0.97538462,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97692308, 0.97538462, 0.97692308, 0.97538462,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.97846154, 0.97538462, 0.97692308,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.97846154, 0.97384615, 0.97692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97846154,\n",
              "        0.97538462, 0.97692308,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.97846154, 0.97538462,\n",
              "        0.97692308,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97692308, 0.97692308, 0.97538462, 0.97692308,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.97692308, 0.96769231, 0.97692308,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.97692308, 0.96923077, 0.97692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97692308,\n",
              "        0.97692308, 0.97692308,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.97692308, 0.97538462,\n",
              "        0.97692308,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97692308, 0.97692308, 0.96461538, 0.97692308,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.97692308, 0.96615385, 0.97692308,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.97692308, 0.98461538, 0.97692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97692308,\n",
              "        0.97692308, 0.97692308,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.97692308, 0.96307692,\n",
              "        0.97692308,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97692308, 0.97692308, 0.97076923, 0.97692308,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.97692308, 0.98      , 0.97692308,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.97692308, 0.98      , 0.97692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97692308,\n",
              "        0.96769231, 0.97692308,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.97692308, 0.97538462,\n",
              "        0.97692308,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97692308, 0.97692308, 0.97846154, 0.97692308,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.97692308, 0.97846154, 0.97692308,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.97692308, 0.96461538, 0.97692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97692308,\n",
              "        0.97076923, 0.97692308,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.97692308, 0.97692308,\n",
              "        0.97692308,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97692308, 0.97692308, 0.97384615, 0.97692308,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97692308, 0.97692308, 0.97538462, 0.97692308,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.97692308, 0.97076923, 0.97692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.97692308,\n",
              "        0.97692308, 0.97692308,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.85230769, 0.86923077, 0.87538462,\n",
              "        0.88461538, 0.91538462, 0.87230769, 0.86923077, 0.86615385,\n",
              "        0.88615385, 0.85538462, 0.88307692, 0.87692308, 0.84769231,\n",
              "        0.87076923, 0.88      , 0.90307692, 0.88      , 0.87230769,\n",
              "        0.73846154, 0.86769231, 0.88      , 0.92769231, 0.87692308,\n",
              "        0.87692308, 0.81076923, 0.87230769, 0.87692308, 0.87692308,\n",
              "        0.88923077, 0.87076923, 0.87692308, 0.86769231, 0.87692308,\n",
              "        0.85230769, 0.88923077, 0.87076923, 0.85846154, 0.89230769,\n",
              "        0.87076923, 0.89230769, 0.89846154, 0.87076923, 0.78923077,\n",
              "        0.87538462, 0.87230769, 0.87846154, 0.89076923, 0.87692308,\n",
              "        0.84923077, 0.88615385, 0.88615385, 0.84615385, 0.87076923,\n",
              "        0.87230769,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99076923, 0.99384615, 0.99384615,\n",
              "        0.99538462, 0.99384615, 0.99384615, 0.99846154, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99538462, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99538462,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99538462, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.87538462, 0.89384615, 0.89230769, 0.78923077, 0.90461538,\n",
              "        0.88153846, 0.87384615, 0.91692308, 0.88      , 0.89538462,\n",
              "        0.91076923, 0.87692308, 0.84769231, 0.86307692, 0.88307692,\n",
              "        0.85384615, 0.89384615, 0.88461538, 0.88153846, 0.90307692,\n",
              "        0.87692308, 0.86615385, 0.88923077, 0.87692308, 0.84307692,\n",
              "        0.92      , 0.89076923, 0.86461538, 0.88      , 0.91230769,\n",
              "        0.88769231, 0.89538462, 0.88615385, 0.92769231, 0.86923077,\n",
              "        0.88923077, 0.88      , 0.88461538, 0.88153846, 0.92923077,\n",
              "        0.89076923, 0.88      , 0.79076923, 0.90769231, 0.88461538,\n",
              "        0.86307692, 0.89384615, 0.88461538, 0.8       , 0.88      ,\n",
              "        0.89230769, 0.87538462, 0.86769231, 0.88615385,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99230769, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99230769, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "        0.99384615, 0.99384615, 0.99384615, 0.99384615, 0.99384615,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        ]),\n",
              " 'split8_test_score': array([       nan,        nan, 0.96923077, 0.95076923, 0.95076923,\n",
              "        0.94923077,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96923077, 0.95076923, 0.95076923, 0.94923077,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96923077, 0.95076923, 0.94923077, 0.94923077,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96923077,\n",
              "        0.95076923, 0.95076923, 0.94923077,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97384615, 0.95692308,\n",
              "        0.95692308, 0.95538462,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97384615, 0.95692308, 0.95538462,\n",
              "        0.95538462,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97384615, 0.95692308, 0.95384615, 0.95538462,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97384615, 0.95692308, 0.95692308, 0.95538462,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97692308,\n",
              "        0.96769231, 0.96307692, 0.96      ,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97692308, 0.96769231,\n",
              "        0.95692308, 0.96      ,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97692308, 0.96769231, 0.96      ,\n",
              "        0.96      ,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97692308, 0.96769231, 0.96153846, 0.96      ,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97846154, 0.97230769, 0.96923077, 0.97076923,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97846154,\n",
              "        0.97230769, 0.97076923, 0.97076923,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97846154, 0.97230769,\n",
              "        0.96307692, 0.97076923,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97846154, 0.97230769, 0.96923077,\n",
              "        0.97076923,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97846154, 0.97692308, 0.96615385, 0.97384615,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97846154, 0.97692308, 0.97076923, 0.97384615,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97846154,\n",
              "        0.97692308, 0.96923077, 0.97384615,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97846154, 0.97692308,\n",
              "        0.97538462, 0.97384615,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97846154, 0.97846154, 0.97230769,\n",
              "        0.97692308,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97846154, 0.97846154, 0.96923077, 0.97692308,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97846154, 0.97846154, 0.97076923, 0.97692308,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97846154,\n",
              "        0.97846154, 0.97692308, 0.97692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97846154, 0.97692308,\n",
              "        0.97076923, 0.97846154,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97846154, 0.97692308, 0.96153846,\n",
              "        0.97846154,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97846154, 0.97692308, 0.97230769, 0.97846154,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97846154, 0.97692308, 0.97384615, 0.97846154,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97846154,\n",
              "        0.97538462, 0.97076923, 0.97692308,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97846154, 0.97538462,\n",
              "        0.97076923, 0.97692308,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97846154, 0.97538462, 0.95384615,\n",
              "        0.97692308,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97846154, 0.97538462, 0.97384615, 0.97692308,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97846154, 0.97538462, 0.97538462, 0.97538462,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97846154,\n",
              "        0.97538462, 0.97230769, 0.97538462,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97846154, 0.97538462,\n",
              "        0.96      , 0.97538462,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97846154, 0.97538462, 0.97538462,\n",
              "        0.97538462,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97846154, 0.97538462, 0.97076923, 0.97538462,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97846154, 0.97538462, 0.97076923, 0.97538462,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97846154,\n",
              "        0.97538462, 0.96153846, 0.97538462,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97846154, 0.97538462,\n",
              "        0.97538462, 0.97538462,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.85692308, 0.87076923, 0.87384615,\n",
              "        0.86      , 0.86307692, 0.87230769, 0.81076923, 0.88      ,\n",
              "        0.88307692, 0.92153846, 0.90923077, 0.88153846, 0.92      ,\n",
              "        0.86923077, 0.87230769, 0.86153846, 0.87230769, 0.87846154,\n",
              "        0.83538462, 0.87538462, 0.9       , 0.85538462, 0.89538462,\n",
              "        0.89846154, 0.83384615, 0.86923077, 0.87692308, 0.84615385,\n",
              "        0.89692308, 0.87230769, 0.81230769, 0.87692308, 0.87230769,\n",
              "        0.84923077, 0.88923077, 0.86461538, 0.91384615, 0.85230769,\n",
              "        0.88769231, 0.80461538, 0.88307692, 0.86307692, 0.93230769,\n",
              "        0.86      , 0.89230769, 0.82307692, 0.89230769, 0.88153846,\n",
              "        0.81230769, 0.86307692, 0.87230769, 0.79846154, 0.86923077,\n",
              "        0.87538462,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.98615385, 0.98769231,\n",
              "        0.98615385, 0.98615385, 0.98769231, 0.98769231, 0.98769231,\n",
              "        0.98615385, 0.98615385, 0.98615385, 0.98769231, 0.98769231,\n",
              "        0.99076923, 0.98615385, 0.98615385, 0.98615385, 0.98615385,\n",
              "        0.98615385, 0.98615385, 0.98769231, 0.98615385, 0.99692308,\n",
              "        0.98769231, 0.98615385, 0.98615385, 0.98615385, 0.98615385,\n",
              "        0.98615385, 0.98615385, 0.98615385, 0.98615385, 0.98769231,\n",
              "        0.98615385, 0.99230769, 0.98769231, 0.98615385, 0.99230769,\n",
              "        0.98615385, 0.98615385, 0.98307692, 0.98615385, 0.98615385,\n",
              "        0.98615385, 0.98615385, 0.98615385, 0.98615385, 0.98615385,\n",
              "        0.98615385, 0.98615385, 0.98615385, 0.98615385, 0.98615385,\n",
              "        0.98615385, 0.98615385,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.86769231, 0.90307692, 0.87692308, 0.79384615, 0.86769231,\n",
              "        0.89538462, 0.88      , 0.86153846, 0.87384615, 0.79846154,\n",
              "        0.86769231, 0.87692308, 0.86      , 0.87692308, 0.89384615,\n",
              "        0.84923077, 0.87076923, 0.87230769, 0.78769231, 0.86307692,\n",
              "        0.88307692, 0.88769231, 0.85538462, 0.88307692, 0.88769231,\n",
              "        0.88      , 0.88769231, 0.88      , 0.85230769, 0.88153846,\n",
              "        0.86307692, 0.86153846, 0.87692308, 0.87692308, 0.87692308,\n",
              "        0.87230769, 0.89846154, 0.85384615, 0.87846154, 0.81538462,\n",
              "        0.90615385, 0.87076923, 0.84769231, 0.87076923, 0.86923077,\n",
              "        0.88615385, 0.86615385, 0.87384615, 0.84769231, 0.85076923,\n",
              "        0.90615385, 0.89538462, 0.88153846, 0.87846154,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.99538462, 0.98769231, 0.98615385, 0.98615385,\n",
              "        0.98769231, 0.98615385, 0.99230769, 0.98615385, 0.98615385,\n",
              "        0.98769231, 0.98769231, 0.98769231, 0.98615385, 0.98615385,\n",
              "        0.98615385, 0.98      , 0.98769231, 0.98615385, 0.98769231,\n",
              "        0.98615385, 0.98615385, 0.98615385, 0.98615385, 0.98615385,\n",
              "        0.98615385, 0.98615385, 0.98615385, 0.98769231, 0.98615385,\n",
              "        0.98615385, 0.98615385, 0.98615385, 0.98615385, 0.99692308,\n",
              "        0.98769231, 0.98615385, 0.98769231, 0.98769231, 0.98615385,\n",
              "        0.97538462, 0.98769231, 0.98615385, 0.98615385, 0.98615385,\n",
              "        0.98615385, 0.98615385, 0.98769231, 0.98615385, 0.99230769,\n",
              "        0.98615385, 0.98615385, 0.98615385, 0.98769231, 0.98615385,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        ]),\n",
              " 'split9_test_score': array([       nan,        nan, 0.95839753, 0.95069337, 0.95223421,\n",
              "        0.95069337,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.95839753, 0.95069337, 0.95069337, 0.95069337,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.95839753, 0.95069337, 0.95069337, 0.95069337,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.95839753,\n",
              "        0.95069337, 0.95069337, 0.95069337,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.96918336, 0.9568567 ,\n",
              "        0.9568567 , 0.95839753,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.96918336, 0.9568567 , 0.95839753,\n",
              "        0.95839753,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96918336, 0.9568567 , 0.95839753, 0.95839753,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96918336, 0.9568567 , 0.95531587, 0.95839753,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97534669,\n",
              "        0.95839753, 0.96302003, 0.95839753,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97534669, 0.95839753,\n",
              "        0.96764253, 0.95839753,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97534669, 0.95839753, 0.95993837,\n",
              "        0.95839753,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97534669, 0.95839753, 0.95993837, 0.95839753,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97534669, 0.96918336, 0.96302003, 0.9614792 ,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97534669,\n",
              "        0.96918336, 0.96764253, 0.9614792 ,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97534669, 0.96918336,\n",
              "        0.9614792 , 0.9614792 ,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97534669, 0.96918336, 0.95993837,\n",
              "        0.9614792 ,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97534669, 0.97226502, 0.96302003, 0.96918336,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97534669, 0.97226502, 0.96918336, 0.96918336,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97534669,\n",
              "        0.97226502, 0.96456086, 0.96918336,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97534669, 0.97226502,\n",
              "        0.96918336, 0.96918336,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97534669, 0.97534669, 0.96456086,\n",
              "        0.97534669,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97534669, 0.97534669, 0.96764253, 0.97534669,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97534669, 0.97534669, 0.96302003, 0.97534669,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97534669,\n",
              "        0.97534669, 0.96918336, 0.97534669,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97534669, 0.97688752,\n",
              "        0.96610169, 0.97534669,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97534669, 0.97688752, 0.96918336,\n",
              "        0.97534669,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97534669, 0.97688752, 0.95993837, 0.97534669,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97534669, 0.97688752, 0.97226502, 0.97534669,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97534669,\n",
              "        0.97688752, 0.96610169, 0.97688752,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97534669, 0.97688752,\n",
              "        0.97072419, 0.97688752,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97534669, 0.97688752, 0.96302003,\n",
              "        0.97688752,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97534669, 0.97688752, 0.96302003, 0.97688752,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97534669, 0.97688752, 0.96610169, 0.97688752,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97534669,\n",
              "        0.97688752, 0.96764253, 0.97688752,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97534669, 0.97688752,\n",
              "        0.96302003, 0.97688752,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97534669, 0.97688752, 0.97842835,\n",
              "        0.97688752,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97534669, 0.97688752, 0.96610169, 0.97688752,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97534669, 0.97688752, 0.96456086, 0.97688752,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97534669,\n",
              "        0.97688752, 0.9614792 , 0.97688752,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97534669, 0.97688752,\n",
              "        0.97534669, 0.97688752,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.83513097, 0.92141757, 0.90292758,\n",
              "        0.93066256, 0.89830508, 0.89214176, 0.86132512, 0.9183359 ,\n",
              "        0.90292758, 0.88906009, 0.90755008, 0.89676425, 0.94453005,\n",
              "        0.86440678, 0.89676425, 0.91679507, 0.90755008, 0.89676425,\n",
              "        0.92141757, 0.90292758, 0.89676425, 0.7550077 , 0.91525424,\n",
              "        0.90292758, 0.82434515, 0.88751926, 0.89676425, 0.83050847,\n",
              "        0.8844376 , 0.90292758, 0.90292758, 0.91217257, 0.90292758,\n",
              "        0.84437596, 0.89830508, 0.89984592, 0.87827427, 0.90446841,\n",
              "        0.90292758, 0.86748844, 0.9183359 , 0.89676425, 0.88906009,\n",
              "        0.9183359 , 0.90292758, 0.90292758, 0.89830508, 0.90292758,\n",
              "        0.87673344, 0.90446841, 0.90292758, 0.89984592, 0.8751926 ,\n",
              "        0.90755008,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.99229584, 0.98767334,\n",
              "        0.98613251, 0.97996918, 0.98613251, 0.98613251, 0.98613251,\n",
              "        0.98613251, 0.98613251, 0.98613251, 0.98613251, 0.98613251,\n",
              "        0.98459168, 0.98613251, 0.98613251, 0.98767334, 0.98613251,\n",
              "        0.98767334, 0.99075501, 0.98767334, 0.98459168, 0.98613251,\n",
              "        0.98459168, 0.98459168, 0.97996918, 0.98613251, 0.98459168,\n",
              "        0.97534669, 0.98613251, 0.98767334, 0.98613251, 0.98613251,\n",
              "        0.98613251, 0.98613251, 0.98613251, 0.98613251, 0.98613251,\n",
              "        0.98613251, 0.98613251, 0.98613251, 0.98613251, 0.98613251,\n",
              "        0.98613251, 0.98613251, 0.98613251, 0.98151002, 0.98613251,\n",
              "        0.98459168, 0.98613251, 0.98459168, 0.98459168, 0.98613251,\n",
              "        0.98459168, 0.98613251,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99845917, 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.99691834, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.99845917, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.90446841, 0.88597843, 0.91063174, 0.91525424, 0.90446841,\n",
              "        0.90755008, 0.87211094, 0.91217257, 0.89830508, 0.92604006,\n",
              "        0.89522342, 0.90755008, 0.83821263, 0.91679507, 0.90755008,\n",
              "        0.82896764, 0.9183359 , 0.89214176, 0.90138675, 0.90755008,\n",
              "        0.89984592, 0.91987673, 0.89984592, 0.91217257, 0.79352851,\n",
              "        0.91217257, 0.91679507, 0.86440678, 0.93220339, 0.91217257,\n",
              "        0.87057011, 0.89060092, 0.91679507, 0.92758089, 0.88597843,\n",
              "        0.90292758, 0.86594761, 0.89676425, 0.91679507, 0.89984592,\n",
              "        0.89676425, 0.91217257, 0.8798151 , 0.90138675, 0.90755008,\n",
              "        0.87827427, 0.92449923, 0.90292758, 0.84437596, 0.89830508,\n",
              "        0.91217257, 0.8412943 , 0.91371341, 0.90755008,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.98305085, 0.98613251, 0.98613251, 0.98305085,\n",
              "        0.98613251, 0.98613251, 0.98767334, 0.98767334, 0.98613251,\n",
              "        0.98613251, 0.98613251, 0.98767334, 0.98613251, 0.98767334,\n",
              "        0.98767334, 0.98151002, 0.98613251, 0.98613251, 0.98459168,\n",
              "        0.98613251, 0.98459168, 0.98459168, 0.98613251, 0.98459168,\n",
              "        0.98459168, 0.98459168, 0.98459168, 0.98613251, 0.98767334,\n",
              "        0.98613251, 0.98613251, 0.98613251, 0.98613251, 0.98767334,\n",
              "        0.98613251, 0.98613251, 0.99383667, 0.98613251, 0.98613251,\n",
              "        0.99383667, 0.98613251, 0.98613251, 0.99075501, 0.98613251,\n",
              "        0.98613251, 0.98767334, 0.98459168, 0.98613251, 0.98459168,\n",
              "        0.98459168, 0.98613251, 0.98613251, 0.98459168, 0.98459168,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        ]),\n",
              " 'mean_test_score': array([       nan,        nan, 0.96445514, 0.9526078 , 0.95245419,\n",
              "        0.95214626,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.96445514, 0.9526078 , 0.95199241, 0.95214626,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.96430129, 0.9526078 , 0.95183857, 0.95214626,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.96460898,\n",
              "        0.9526078 , 0.9526078 , 0.95214626,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97076449, 0.95691644,\n",
              "        0.95753182, 0.95660898,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97122603, 0.95691644, 0.95614745,\n",
              "        0.95660898,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97091834, 0.95691644, 0.95583975, 0.95660898,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97076449, 0.95691644, 0.95707005, 0.95660898,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97338082,\n",
              "        0.96337822, 0.96384046, 0.9619936 ,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97338082, 0.96337822,\n",
              "        0.96107195, 0.9619936 ,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97338082, 0.96337822, 0.95999384,\n",
              "        0.9619936 ,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97338082, 0.96337822, 0.96322461, 0.9619936 ,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97338082, 0.96984141, 0.96645585, 0.96722484,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97384236,\n",
              "        0.96984141, 0.96184118, 0.96722484,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97384236, 0.96984141,\n",
              "        0.9627633 , 0.96722484,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97384236, 0.96984141, 0.96768614,\n",
              "        0.96722484,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97384236, 0.97307266, 0.96645585, 0.97137987,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97399621, 0.97307266, 0.9624568 , 0.97137987,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97415005,\n",
              "        0.97307266, 0.9618407 , 0.97137987,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97399621, 0.97307266,\n",
              "        0.97230295, 0.97137987,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97415005, 0.97399621, 0.96753301,\n",
              "        0.97384236,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97399621, 0.97399621, 0.96214887, 0.97384236,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97415005, 0.97399621, 0.96091739, 0.97384236,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97415005,\n",
              "        0.97399621, 0.97322603, 0.97384236,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97415005, 0.97353491,\n",
              "        0.9673794 , 0.97384236,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97415005, 0.97353491, 0.96107218,\n",
              "        0.97384236,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97415005, 0.97353491, 0.9635323 , 0.97384236,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97415005, 0.97353491, 0.97307266, 0.97384236,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97415005,\n",
              "        0.97307337, 0.96784094, 0.97338106,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97415005, 0.97307337,\n",
              "        0.96245703, 0.97338106,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97415005, 0.97307337, 0.96414816,\n",
              "        0.97338106,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97415005, 0.97307337, 0.97107123, 0.97338106,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97415005, 0.97307337, 0.96814863, 0.97322721,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97399621,\n",
              "        0.97307337, 0.96276425, 0.97322721,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97415005, 0.97307337,\n",
              "        0.96384046, 0.97322721,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.97415005, 0.97307337, 0.9730736 ,\n",
              "        0.97322721,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.97399621, 0.97322721, 0.96676402, 0.97307337,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.97415005, 0.97322721, 0.96153301, 0.97307337,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.97415005,\n",
              "        0.97322721, 0.96214792, 0.97307337,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.97399621, 0.97322721,\n",
              "        0.97168851, 0.97307337,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.84997464, 0.8846033 , 0.88660045,\n",
              "        0.88091241, 0.88721512, 0.88259879, 0.84659405, 0.89060282,\n",
              "        0.88413891, 0.86413678, 0.89337039, 0.88875335, 0.8747607 ,\n",
              "        0.88520991, 0.8845995 , 0.87521797, 0.88675501, 0.88413796,\n",
              "        0.84768022, 0.8967543 , 0.8885995 , 0.85196231, 0.88583312,\n",
              "        0.88690814, 0.83843451, 0.883675  , 0.88444566, 0.85043546,\n",
              "        0.88736684, 0.8867543 , 0.8767543 , 0.88475572, 0.88460045,\n",
              "        0.86274529, 0.88444589, 0.87998459, 0.87182743, 0.8859853 ,\n",
              "        0.88752353, 0.86290269, 0.89337205, 0.88352258, 0.84598293,\n",
              "        0.88214128, 0.88598507, 0.83906199, 0.89198435, 0.8847543 ,\n",
              "        0.85875027, 0.88613915, 0.88552353, 0.86059998, 0.87536541,\n",
              "        0.88537039,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.98984497, 0.99045964,\n",
              "        0.98969017, 0.98984307, 0.98999787, 0.98984402, 0.98999787,\n",
              "        0.98999787, 0.98984402, 0.98953633, 0.98999787, 0.98969017,\n",
              "        0.9892284 , 0.98969017, 0.98953633, 0.98969041, 0.99030556,\n",
              "        0.9899981 , 0.98984473, 0.98938272, 0.98892071, 0.99107479,\n",
              "        0.98907455, 0.98892071, 0.98830461, 0.98938248, 0.98892071,\n",
              "        0.98938082, 0.98953633, 0.98984426, 0.98953633, 0.98999787,\n",
              "        0.98984402, 0.98799787, 0.99030556, 0.98984402, 0.99045941,\n",
              "        0.99015171, 0.98984402, 0.99030556, 0.98969017, 0.98984402,\n",
              "        0.99045941, 0.98999787, 0.98953633, 0.98892023, 0.98938248,\n",
              "        0.98892071, 0.98907479, 0.98907455, 0.98892071, 0.98953633,\n",
              "        0.98938224, 0.98892094,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99907669, 1.        , 1.        ,\n",
              "        0.99953846, 1.        , 1.        , 0.99969183, 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 0.99984592, 1.        , 1.        , 0.99984615,\n",
              "        1.        , 1.        , 0.99984615, 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.8759853 , 0.89029015, 0.88629394, 0.85691004, 0.88644684,\n",
              "        0.8870627 , 0.86351879, 0.88783264, 0.88383051, 0.86675785,\n",
              "        0.88783003, 0.88337039, 0.86243665, 0.89075643, 0.8870627 ,\n",
              "        0.85428138, 0.88614128, 0.88475264, 0.8532156 , 0.89013962,\n",
              "        0.88721536, 0.86814152, 0.88659998, 0.88583264, 0.87089131,\n",
              "        0.88598649, 0.88967951, 0.87136375, 0.88352803, 0.8916788 ,\n",
              "        0.85844163, 0.87998317, 0.88614105, 0.8741427 , 0.87629015,\n",
              "        0.8864466 , 0.87874861, 0.87475335, 0.88691028, 0.86859998,\n",
              "        0.8905995 , 0.8856788 , 0.85751997, 0.8852156 , 0.88552424,\n",
              "        0.87398127, 0.88952685, 0.88383122, 0.85689913, 0.87090743,\n",
              "        0.8913711 , 0.86382174, 0.89398673, 0.88444732,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.99107432, 0.98984402, 0.98953633, 0.98922816,\n",
              "        0.98999787, 0.98984402, 0.99045964, 0.99015195, 0.98969017,\n",
              "        0.98984402, 0.99061325, 0.9899981 , 0.99030556, 0.9899981 ,\n",
              "        0.9899981 , 0.98707408, 0.98999787, 0.98984402, 0.98984378,\n",
              "        0.98969017, 0.98892071, 0.98953609, 0.98999787, 0.9892284 ,\n",
              "        0.98953609, 0.9892284 , 0.98892071, 0.99092094, 0.9903058 ,\n",
              "        0.98969017, 0.98907479, 0.98999787, 0.98984402, 0.99215195,\n",
              "        0.99030556, 0.98999787, 0.98922982, 0.98999787, 0.98984402,\n",
              "        0.98969136, 0.98999787, 0.98984402, 0.98984473, 0.99030556,\n",
              "        0.98984402, 0.98953657, 0.98907455, 0.98922864, 0.98784378,\n",
              "        0.98892071, 0.98907479, 0.99015171, 0.98968994, 0.98892071,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 0.99969231, 0.99984615,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        , 1.        , 0.99984615, 0.99984615, 1.        ,\n",
              "        0.99953846, 0.99969231, 1.        , 1.        , 1.        ,\n",
              "        1.        ]),\n",
              " 'std_test_score': array([       nan,        nan, 0.00871951, 0.00975099, 0.00990979,\n",
              "        0.00969342,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.00871951, 0.00975099, 0.00984713, 0.00969342,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.00856465, 0.00975099, 0.0094107 , 0.00969342,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.008515  ,\n",
              "        0.00975099, 0.00975099, 0.00969342,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.00694973, 0.00965685,\n",
              "        0.00870878, 0.01008252,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.0074131 , 0.00965685, 0.01070726,\n",
              "        0.01008252,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.00675818, 0.00965685, 0.01092156, 0.01008252,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.00694973, 0.00965685, 0.01002954, 0.01008252,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.00663568,\n",
              "        0.00922907, 0.00971229, 0.00943734,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.00663568, 0.00922907,\n",
              "        0.0095313 , 0.00943734,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.00663568, 0.00922907, 0.01081311,\n",
              "        0.00943734,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.00663568, 0.00922907, 0.00944708, 0.00943734,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.0065278 , 0.00674867, 0.00842319, 0.00722236,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.00626725,\n",
              "        0.00674867, 0.00942557, 0.00722236,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.00626725, 0.00674867,\n",
              "        0.00987092, 0.00722236,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.00626725, 0.00674867, 0.0080883 ,\n",
              "        0.00722236,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.00641653, 0.00664445, 0.00842319, 0.00678472,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.00624654, 0.00664445, 0.00902501, 0.00678472,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.00610676,\n",
              "        0.00664445, 0.00891078, 0.00678472,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.00624654, 0.00664445,\n",
              "        0.00778595, 0.00678472,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.00610676, 0.00624654, 0.00841295,\n",
              "        0.00637954,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.00624654, 0.00624654, 0.00960976, 0.00637954,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.00610676, 0.00624654, 0.01180009, 0.00637954,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.00610676,\n",
              "        0.00624654, 0.00705953, 0.00637954,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.00610676, 0.0062587 ,\n",
              "        0.00907112, 0.00599707,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.00610676, 0.0062587 , 0.01029476,\n",
              "        0.00599707,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.00610676, 0.0062587 , 0.00859731, 0.00599707,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.00610676, 0.0062587 , 0.00763871, 0.00599707,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.00610676,\n",
              "        0.00660616, 0.00893071, 0.00641732,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.00610676, 0.00660616,\n",
              "        0.01045797, 0.00641732,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.00610676, 0.00660616, 0.00711949,\n",
              "        0.00641732,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.00610676, 0.00660616, 0.00787455, 0.00641732,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.00610676, 0.00660616, 0.00865088, 0.00634864,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.00624654,\n",
              "        0.00660616, 0.00890972, 0.00634864,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.00610676, 0.00660616,\n",
              "        0.00702554, 0.00634864,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.00610676, 0.00660616, 0.00751093,\n",
              "        0.00634864,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.00605412, 0.00660446, 0.00772957, 0.00660616,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.00610676, 0.00660446, 0.01015687, 0.00660616,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.00610676,\n",
              "        0.00660446, 0.00961301, 0.00660616,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.00577397, 0.00660446,\n",
              "        0.00766583, 0.00660616,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.02674294, 0.02021326, 0.01103015,\n",
              "        0.05047915, 0.01868217, 0.00934229, 0.03640478, 0.01894214,\n",
              "        0.01277683, 0.03135026, 0.01778496, 0.01178722, 0.04630582,\n",
              "        0.01399958, 0.00978294, 0.03726253, 0.01061308, 0.01061868,\n",
              "        0.063381  , 0.01826895, 0.01035802, 0.05077954, 0.01566175,\n",
              "        0.01194138, 0.03997393, 0.02052464, 0.00896063, 0.03467504,\n",
              "        0.01197659, 0.01509223, 0.04050448, 0.01473845, 0.01130197,\n",
              "        0.02291892, 0.01738569, 0.01148609, 0.03925057, 0.01541993,\n",
              "        0.01110411, 0.03321828, 0.01583527, 0.01393402, 0.0543377 ,\n",
              "        0.01870703, 0.00939285, 0.05025458, 0.02042597, 0.00985814,\n",
              "        0.02802663, 0.01502436, 0.01054935, 0.06363595, 0.01353509,\n",
              "        0.01264749,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan, 0.00413887, 0.00246368,\n",
              "        0.00308322, 0.003972  , 0.00317421, 0.00324418, 0.00324792,\n",
              "        0.0030214 , 0.00331633, 0.00342843, 0.00317421, 0.00300548,\n",
              "        0.00370806, 0.00308322, 0.00314017, 0.00491663, 0.00344612,\n",
              "        0.00268844, 0.00596616, 0.00318752, 0.00356467, 0.00321568,\n",
              "        0.00347398, 0.00369508, 0.00525372, 0.00295763, 0.00356467,\n",
              "        0.00540325, 0.00314017, 0.00293659, 0.00328746, 0.00317421,\n",
              "        0.00331633, 0.00591125, 0.00248903, 0.00338695, 0.0045032 ,\n",
              "        0.00317059, 0.00331633, 0.00456835, 0.00337635, 0.00285619,\n",
              "        0.00321527, 0.00324792, 0.00314017, 0.00394572, 0.00326206,\n",
              "        0.00356467, 0.00367151, 0.00340517, 0.00369508, 0.00356383,\n",
              "        0.00354166, 0.00342805,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00102064, 0.        , 0.        ,\n",
              "        0.0009851 , 0.        , 0.        , 0.0009245 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00046225, 0.        , 0.        , 0.00046154,\n",
              "        0.        , 0.        , 0.00046154, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "        0.02193511, 0.01724675, 0.01287229, 0.04647469, 0.02315553,\n",
              "        0.01370812, 0.02665873, 0.02457744, 0.00980975, 0.05390479,\n",
              "        0.01507286, 0.01496889, 0.04501011, 0.01677683, 0.01085602,\n",
              "        0.02991784, 0.01845241, 0.01161364, 0.0503296 , 0.01652898,\n",
              "        0.01147621, 0.03162916, 0.0139684 , 0.01578394, 0.04326231,\n",
              "        0.02096999, 0.01563762, 0.02973496, 0.01997517, 0.01486868,\n",
              "        0.02910883, 0.01823242, 0.01469757, 0.04171065, 0.01989887,\n",
              "        0.01550348, 0.0319386 , 0.01547234, 0.0152087 , 0.04044815,\n",
              "        0.01740613, 0.01378678, 0.04019156, 0.01900681, 0.01663919,\n",
              "        0.02098299, 0.02043412, 0.01027528, 0.03372886, 0.01684787,\n",
              "        0.01433346, 0.03544184, 0.01785332, 0.01428464,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan, 0.00466071, 0.00309482, 0.00314017, 0.00357956,\n",
              "        0.0030214 , 0.00331633, 0.00298495, 0.00316936, 0.00308322,\n",
              "        0.00309482, 0.00261903, 0.00277508, 0.00300591, 0.003173  ,\n",
              "        0.00268844, 0.00555837, 0.00324792, 0.00331633, 0.00293943,\n",
              "        0.00308322, 0.00356467, 0.0027391 , 0.00332   , 0.00337385,\n",
              "        0.00328881, 0.00337385, 0.00369508, 0.00437816, 0.00275819,\n",
              "        0.00323311, 0.00279276, 0.00359386, 0.00331633, 0.00252662,\n",
              "        0.00315947, 0.00309875, 0.00461444, 0.0030214 , 0.00331633,\n",
              "        0.0055056 , 0.00317421, 0.00331633, 0.00612279, 0.00292611,\n",
              "        0.00317038, 0.00313898, 0.00354146, 0.00351011, 0.0092687 ,\n",
              "        0.00328837, 0.00340389, 0.00293811, 0.00300697, 0.00356467,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan,        nan,        nan,        nan,\n",
              "               nan,        nan, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.00092308, 0.00046154,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00046154, 0.00046154, 0.        ,\n",
              "        0.0009851 , 0.00061538, 0.        , 0.        , 0.        ,\n",
              "        0.        ]),\n",
              " 'rank_test_score': array([485, 485, 324, 365, 370, 371, 485, 485, 485, 485, 485, 324, 365,\n",
              "        375, 371, 485, 485, 485, 485, 485, 326, 365, 376, 371, 485, 485,\n",
              "        485, 485, 485, 323, 365, 365, 371, 485, 485, 485, 485, 485, 305,\n",
              "        355, 353, 359, 485, 485, 485, 485, 485, 302, 355, 363, 359, 485,\n",
              "        485, 485, 485, 485, 304, 355, 364, 359, 485, 485, 485, 485, 485,\n",
              "        305, 355, 354, 359, 485, 485, 485, 485, 485, 264, 331, 328, 342,\n",
              "        485, 485, 485, 485, 485, 264, 331, 350, 342, 485, 485, 485, 485,\n",
              "        485, 264, 331, 352, 342, 485, 485, 485, 485, 485, 264, 331, 335,\n",
              "        342, 485, 485, 485, 485, 485, 268, 307, 321, 316, 485, 485, 485,\n",
              "        485, 485, 244, 307, 346, 316, 485, 485, 485, 485, 485, 244, 307,\n",
              "        337, 316, 485, 485, 485, 485, 485, 244, 307, 313, 316, 485, 485,\n",
              "        485, 485, 485, 244, 291, 321, 298, 485, 485, 485, 485, 485, 234,\n",
              "        291, 339, 298, 485, 485, 485, 485, 485, 217, 291, 347, 298, 485,\n",
              "        485, 485, 485, 485, 234, 291, 296, 298, 485, 485, 485, 485, 485,\n",
              "        217, 234, 314, 244, 485, 485, 485, 485, 485, 234, 234, 340, 244,\n",
              "        485, 485, 485, 485, 485, 217, 234, 351, 244, 485, 485, 485, 485,\n",
              "        485, 217, 234, 277, 244, 485, 485, 485, 485, 485, 217, 256, 315,\n",
              "        244, 485, 485, 485, 485, 485, 217, 256, 349, 244, 485, 485, 485,\n",
              "        485, 485, 217, 256, 330, 244, 485, 485, 485, 485, 485, 217, 256,\n",
              "        291, 244, 485, 485, 485, 485, 485, 217, 279, 312, 260, 485, 485,\n",
              "        485, 485, 485, 217, 279, 338, 260, 485, 485, 485, 485, 485, 217,\n",
              "        279, 327, 260, 485, 485, 485, 485, 485, 217, 279, 303, 260, 485,\n",
              "        485, 485, 485, 485, 217, 279, 311, 269, 485, 485, 485, 485, 485,\n",
              "        234, 279, 336, 269, 485, 485, 485, 485, 485, 217, 279, 328, 269,\n",
              "        485, 485, 485, 485, 485, 217, 279, 278, 269, 485, 485, 485, 485,\n",
              "        485, 234, 269, 320, 279, 485, 485, 485, 485, 485, 217, 269, 348,\n",
              "        279, 485, 485, 485, 485, 485, 217, 269, 341, 279, 485, 485, 485,\n",
              "        485, 485, 234, 269, 297, 279, 485, 485, 485, 485, 485, 485, 485,\n",
              "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
              "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 479, 427, 405,\n",
              "        443, 398, 441, 481, 385, 433, 463, 380, 391, 452, 423, 429, 451,\n",
              "        403, 434, 480, 377, 392, 477, 416, 402, 484, 437, 432, 478, 396,\n",
              "        404, 447, 424, 428, 467, 431, 444, 456, 414, 395, 466, 379, 439,\n",
              "        482, 442, 415, 483, 381, 425, 470, 412, 420, 469, 450, 421, 485,\n",
              "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
              "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
              "        145, 114, 169, 164, 132, 149, 132, 136, 149, 176, 136, 167, 192,\n",
              "        169, 176, 166, 119, 128, 146, 185, 203, 110, 199, 203, 213, 186,\n",
              "        203, 189, 176, 148, 176, 136, 149, 214, 119, 149, 116, 126, 149,\n",
              "        119, 169, 149, 117, 136, 176, 212, 186, 203, 196, 199, 203, 176,\n",
              "        188, 202, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
              "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
              "        485, 485, 485,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
              "          1,   1,   1,   1,   1,   1,   1,   1, 108,   1,   1, 106,   1,\n",
              "          1, 105,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
              "          1,   1,   1,   1,   1,   1, 102,   1,   1,  97,   1,   1,  97,\n",
              "          1,   1,   1,   1,   1, 485, 485, 485, 485, 485, 485, 485, 485,\n",
              "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
              "        485, 485, 485, 485, 485, 485, 449, 387, 409, 473, 407, 399, 465,\n",
              "        393, 436, 462, 394, 440, 468, 384, 400, 475, 410, 426, 476, 388,\n",
              "        397, 461, 406, 417, 459, 413, 389, 457, 438, 382, 471, 445, 411,\n",
              "        454, 448, 408, 446, 453, 401, 460, 386, 418, 472, 422, 419, 455,\n",
              "        390, 435, 474, 458, 383, 464, 378, 430, 485, 485, 485, 485, 485,\n",
              "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
              "        485, 485, 485, 485, 485, 485, 485, 485, 485, 111, 149, 176, 195,\n",
              "        132, 149, 114, 125, 169, 149, 113, 128, 119, 128, 128, 216, 136,\n",
              "        149, 163, 169, 203, 183, 136, 192, 183, 192, 203, 112, 118, 167,\n",
              "        196, 136, 149, 109, 119, 136, 190, 132, 149, 165, 136, 149, 147,\n",
              "        119, 149, 175, 199, 191, 215, 203, 196, 126, 174, 203, 485, 485,\n",
              "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,\n",
              "        485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485, 485,   1,\n",
              "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
              "          1,   1,   1,   1,   1,   1,   1, 103,  97,   1,   1,   1,   1,\n",
              "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
              "          1,   1,   1,   1,   1,  97,  97,   1, 106, 103,   1,   1,   1,\n",
              "          1], dtype=int32)}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_df= pd.DataFrame(gridSearch.cv_results_)[['max_depth','n_estimators','mean_test_score']]\n",
        "grid_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "i1FHorrYuEfk",
        "outputId": "17ff0dc3-42f6-489a-add2-4a62ab16bb39"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['max_depth', 'n_estimators'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-70f591abde5f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_df\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgridSearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgrid_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3898\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3899\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6113\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6115\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6117\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6178\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6179\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6181\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['max_depth', 'n_estimators'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_0wUiyvvm7X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}